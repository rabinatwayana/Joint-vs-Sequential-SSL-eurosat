{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1663377,"sourceType":"datasetVersion","datasetId":918039}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"e0cb307d","cell_type":"markdown","source":"## Self Supervised Learning (SSL)","metadata":{}},{"id":"3266bf3c","cell_type":"code","source":"!pip install torchgeo --quiet\n!pip install lightning --quiet\n!pip install prettytable","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T08:22:54.872979Z","iopub.execute_input":"2026-02-14T08:22:54.874068Z","iopub.status.idle":"2026-02-14T08:23:15.377095Z","shell.execute_reply.started":"2026-02-14T08:22:54.874029Z","shell.execute_reply":"2026-02-14T08:23:15.375837Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m652.1/652.1 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.1/246.1 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m859.3/859.3 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m853.6/853.6 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.6/165.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.5/760.5 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: prettytable in /usr/local/lib/python3.12/dist-packages (3.16.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prettytable) (0.2.14)\n","output_type":"stream"}],"execution_count":1},{"id":"fce313a0","cell_type":"code","source":"import os\nSEED = 42\n# Environment variables\nos.environ[\"PYTHONHASHSEED\"] = str(SEED)\n# os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T08:23:15.379706Z","iopub.execute_input":"2026-02-14T08:23:15.379995Z","iopub.status.idle":"2026-02-14T08:23:15.385158Z","shell.execute_reply.started":"2026-02-14T08:23:15.379966Z","shell.execute_reply":"2026-02-14T08:23:15.384351Z"}},"outputs":[],"execution_count":2},{"id":"c72eb59f-1500-4e39-b46c-556d5a33e05f","cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\n# os.cpu_count()\ntorch.cuda.is_available()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T08:23:15.386243Z","iopub.execute_input":"2026-02-14T08:23:15.386522Z","iopub.status.idle":"2026-02-14T08:23:15.406969Z","shell.execute_reply.started":"2026-02-14T08:23:15.386498Z","shell.execute_reply":"2026-02-14T08:23:15.406073Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}],"execution_count":3},{"id":"90794fb4-bc3f-48cf-a840-cbe31a22fcd7","cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nimport rasterio\nimport numpy as np\nfrom rasterio.enums import Resampling\nimport torch.nn as nn\nimport pytorch_lightning as pl\nfrom torchvision.models import resnet50\nfrom torch.utils.data import DataLoader\nfrom lightning.pytorch import Trainer\nfrom torchvision import transforms  \nfrom torchgeo.trainers.moco import MoCoTask\nfrom torchgeo.models import ResNet50_Weights\nimport kornia.augmentation as K\nimport torch.nn.functional as F\nimport torchgeo.transforms as T\nfrom lightning.pytorch.loggers import CSVLogger\nimport glob\nimport shutil\nimport random\nimport time\nfrom prettytable import PrettyTable\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T08:23:15.409203Z","iopub.execute_input":"2026-02-14T08:23:15.409546Z","iopub.status.idle":"2026-02-14T08:23:37.707968Z","shell.execute_reply.started":"2026-02-14T08:23:15.409516Z","shell.execute_reply":"2026-02-14T08:23:37.707030Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":4},{"id":"af5f7783-8984-445f-86c3-c0d095d433fe","cell_type":"code","source":"random.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\npl.seed_everything(SEED, workers=True)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.use_deterministic_algorithms(True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T08:23:37.709390Z","iopub.execute_input":"2026-02-14T08:23:37.709918Z","iopub.status.idle":"2026-02-14T08:23:37.726298Z","shell.execute_reply.started":"2026-02-14T08:23:37.709883Z","shell.execute_reply":"2026-02-14T08:23:37.725357Z"}},"outputs":[{"name":"stderr","text":"Seed set to 42\n","output_type":"stream"}],"execution_count":5},{"id":"795ed230-3932-4ff3-bb39-e13f7b081e2a","cell_type":"code","source":"import os\nimport pandas as pd\n\n# --- CONFIG ---\nroot_dir = \"/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT\"  # folder with all images\ncsv_output = \"/kaggle/working/eurosat_split.csv\"\n\n# --- COLLECT IMAGE INFO ---\ndata=[]\n# Iterate over each class folder\nfor class_name in os.listdir(root_dir):\n    class_path = os.path.join(root_dir, class_name)\n    print(class_path)\n    if not os.path.isdir(class_path):\n        continue  # skip files in root_dir\n\n    # Iterate over images in the class folder\n    for fname in os.listdir(class_path):\n        if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n            path = os.path.join(class_path, fname)\n            \n            data.append({\n                \"id\": os.path.splitext(fname)[0].split(\"_\")[-1],\n                 \"fname\": fname,\n                \"path\": path,\n                \"label\": class_name\n            })\n    \n\n# --- CREATE DATAFRAME ---\ndf = pd.DataFrame(data)\n\n# --- STRATIFIED SPLIT: 80% SSL, 20% Downstream ---\nssl_df, downstream_df = train_test_split(\n    df,\n    test_size=0.2,\n    stratify=df['label'],\n    random_state=42\n)\n\nssl_df['task'] = 'ssl'\ndownstream_df['task'] = 'downstream'\n\ndf = pd.concat([ssl_df, downstream_df]).reset_index(drop=True)\n\nssl_df = df[df['task'] == 'ssl'].copy()\n\nskf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n\nssl_splits = np.empty(len(ssl_df), dtype=object)\nsplit_names = ['subst1', 'subst2', 'subst3', 'subst4']\n\nfor fold_idx, (_, val_idx) in enumerate(skf.split(ssl_df, ssl_df['label'])):\n    ssl_splits[val_idx] = split_names[fold_idx]\n\ndf.loc[ssl_df.index, 'split'] = ssl_splits\n\n\n\n\ndown_df = df[df['task'] == 'downstream'].copy()\n\n# Step 1: Train (70%) vs Temp (30%)\ntrain_df, temp_df = train_test_split(\n    down_df,\n    test_size=0.30,\n    stratify=down_df['label'],\n    random_state=42\n)\n\n# Step 2: Temp → Val (15%) + Test (15%)\nval_df, test_df = train_test_split(\n    temp_df,\n    test_size=0.50,  # half of 30% = 15%\n    stratify=temp_df['label'],\n    random_state=42\n)\n\n# Assign splits back\ndf.loc[train_df.index, 'split'] = 'train'\ndf.loc[val_df.index, 'split'] = 'val'\ndf.loc[test_df.index, 'split'] = 'test'\n\n\n\n\n# --- FINAL CHECK ---\nprint(df['task'].value_counts())\nprint(df['split'].value_counts())\n# print(df.head(10))\n\n# --- SAVE CSV ---\ndf.to_csv(csv_output, index=False)\nprint(f\"CSV saved to {csv_output}\")\nprint(df.head())\nprint(df[df['split'] == 'train']['label'].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T08:24:20.307100Z","iopub.execute_input":"2026-02-14T08:24:20.307407Z","iopub.status.idle":"2026-02-14T08:24:20.707107Z","shell.execute_reply.started":"2026-02-14T08:24:20.307379Z","shell.execute_reply":"2026-02-14T08:24:20.705957Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/SeaLake\n/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/Highway\n/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/River\n/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/Pasture\n/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/Industrial\n/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/Residential\n/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/PermanentCrop\n/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/validation.csv\n/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/AnnualCrop\n/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/train.csv\n/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/test.csv\n/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/label_map.json\n/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/Forest\n/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/HerbaceousVegetation\ntask\nssl           21600\ndownstream     5400\nName: count, dtype: int64\nsplit\nsubst4    5400\nsubst1    5400\nsubst2    5400\nsubst3    5400\ntrain     3780\ntest       810\nval        810\nName: count, dtype: int64\nCSV saved to /kaggle/working/eurosat_split.csv\n     id                  fname  \\\n0  1484    AnnualCrop_1484.jpg   \n1   682  PermanentCrop_682.jpg   \n2  2649       SeaLake_2649.jpg   \n3  2776       SeaLake_2776.jpg   \n4  2372   Residential_2372.jpg   \n\n                                                path          label task  \\\n0  /kaggle/input/datasets/apollo2506/eurosat-data...     AnnualCrop  ssl   \n1  /kaggle/input/datasets/apollo2506/eurosat-data...  PermanentCrop  ssl   \n2  /kaggle/input/datasets/apollo2506/eurosat-data...        SeaLake  ssl   \n3  /kaggle/input/datasets/apollo2506/eurosat-data...        SeaLake  ssl   \n4  /kaggle/input/datasets/apollo2506/eurosat-data...    Residential  ssl   \n\n    split  \n0  subst4  \n1  subst4  \n2  subst1  \n3  subst2  \n4  subst1  \n","output_type":"stream"}],"execution_count":8},{"id":"a8fe5a1d-bd2e-4641-899d-5e419a396b7b","cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T08:24:53.968891Z","iopub.execute_input":"2026-02-14T08:24:53.969390Z","iopub.status.idle":"2026-02-14T08:24:53.980642Z","shell.execute_reply.started":"2026-02-14T08:24:53.969356Z","shell.execute_reply":"2026-02-14T08:24:53.979440Z"}},"outputs":[{"name":"stdout","text":"label\nAnnualCrop              420\nHerbaceousVegetation    420\nResidential             420\nSeaLake                 420\nForest                  420\nIndustrial              350\nHighway                 350\nPermanentCrop           350\nRiver                   350\nPasture                 280\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":9},{"id":"890b261c-7189-4b2b-9c11-4324424c958a","cell_type":"code","source":"class SSLDataset(Dataset):\n    def __init__(self, scenes, bands, transforms=None):\n        \"\"\"\n        Args:\n            scenes (list): List of scene folder paths.\n            bands (list): List of band names (e.g., [\"B1\",\"B2\"]).\n            patch_size (tuple): Size of random crop (H, W).\n            transforms (callable, optional): Optional transform to apply to patches.\n        \"\"\"\n        self.scenes = scenes\n        self.bands = bands\n        # self.patch_size = patch_size\n        self.transforms = transforms\n        self.target_h= None\n        self.target_w = None\n        \n\n        # Precompute all timestamp paths to treat each timestamp as a sample\n        self.samples = []\n        for scene_path in scenes:\n            timestamps = sorted([\n                d for d in os.listdir(scene_path)\n                if os.path.isdir(os.path.join(scene_path, d))\n            ])\n            for ts in timestamps:\n                self.samples.append(os.path.join(scene_path, ts))\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        ts_path = self.samples[idx]\n\n        with rasterio.open(os.path.join(ts_path, \"B2.tif\")) as src:\n            target_h, target_w = src.height, src.width\n            # print(target_h,target_w, \"target width and height\" )\n\n        band_arrays = []\n\n        for b in self.bands:\n            path = os.path.join(ts_path, f\"{b}.tif\")\n            with rasterio.open(path) as src:\n                if src.height == target_h and src.width == target_w:\n                    arr = src.read(1).astype(np.float32)\n                else:\n                    arr = src.read(\n                        1,\n                        out_shape=(target_h, target_w),\n                        resampling=Resampling.bilinear\n                    ).astype(np.float32)\n\n            band_arrays.append(arr)\n\n        # Insert fake B10\n        insert_idx = 10\n        b10_pad = np.zeros((target_h, target_w), dtype=np.float32)\n        band_arrays.insert(insert_idx, b10_pad)\n\n        img = np.stack(band_arrays, axis=0)\n\n        # img_patch = self._random_crop(img)\n\n        patch_tensor = torch.tensor(img, dtype=torch.float32)\n\n        if self.transforms:\n            patch_tensor = self.transforms(patch_tensor)\n\n        return {\"image\": patch_tensor}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"0d972eb3-7c40-4ba8-9d4d-52f5ca7e243b","cell_type":"code","source":"from torchgeo.datasets import EuroSAT\n\ndataset= EuroSAT(root='/kaggle/input/datasets/apollo2506/eurosat-dataset/')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T21:30:48.039676Z","iopub.execute_input":"2026-02-12T21:30:48.039932Z","iopub.status.idle":"2026-02-12T21:30:48.048860Z","shell.execute_reply.started":"2026-02-12T21:30:48.039908Z","shell.execute_reply":"2026-02-12T21:30:48.048029Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mDatasetNotFoundError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/1705812584.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchgeo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEuroSAT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mEuroSAT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/kaggle/input/datasets/apollo2506/eurosat-dataset/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchgeo/datasets/eurosat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, split, bands, transforms, download, checksum)\u001b[0m\n\u001b[1;32m    146\u001b[0m         ).long()\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mvalid_fns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchgeo/datasets/eurosat.py\u001b[0m in \u001b[0;36m_verify\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 )\n\u001b[1;32m    194\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mDatasetNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# Check image directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mDatasetNotFoundError\u001b[0m: Dataset not found in `root='/kaggle/input/datasets/apollo2506/eurosat-dataset/'` and `download=False`, either specify a different `root` or use `download=True` to automatically download the dataset."],"ename":"DatasetNotFoundError","evalue":"Dataset not found in `root='/kaggle/input/datasets/apollo2506/eurosat-dataset/'` and `download=False`, either specify a different `root` or use `download=True` to automatically download the dataset.","output_type":"error"}],"execution_count":9},{"id":"ac249289-34f6-466f-805f-de6a073212ea","cell_type":"code","source":"\nSub-sample 3k Data\n\n# root_dir = \"/Volumes/WD_Rabina/competition/extracted_data/s2a\"\n# # List all folders\n# scenes = sorted(glob.glob(os.path.join(root_dir, \"*/\")))\n# # print(scenes)\n# print(len(scenes))\n\n# no_of_files=3000\n\n# # Randomly select 3000 scenes (without replacement)\n# selected_scenes = random.sample(scenes, k=3000)\n\n# print(f\"Total selected scenes: {len(selected_scenes)}\")\n# # print(selected_scenes[:10])  # show first 10 for sanity check\n\n# # Path to new folder where selected scenes will be copied\n# destination_root = \"data/s2a_3k_sample\"\n# os.makedirs(destination_root, exist_ok=True)  # create folder if it doesn't exist\n\n# # Copy each selected folder\n# count=0\n# for scene_path in selected_scenes:\n#     # Get folder name only (e.g., \"000015\")\n#     folder_name = os.path.basename(os.path.normpath(scene_path))\n    \n#     # Destination path\n#     dest_path = os.path.join(destination_root, folder_name)\n#     count=count+1\n#     print(count)\n#     # Copy folder and all its contents\n#     shutil.copytree(scene_path, dest_path)\n\n# print(f\"Copied {len(selected_scenes)} folders to {destination_root}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"ddf46e52-f888-4f43-a96a-b01575896bad","cell_type":"markdown","source":"### Settings","metadata":{}},{"id":"b1524f2e-eafe-4421-8fc2-bf32635eda5c","cell_type":"code","source":"target_size = 224\ntarget_batch_size= 8 #128 #prefer 256 or 128\ntarget_num_workers=4\ntarget_max_epoch=6\nuse_peft = True  \nfrom datetime import datetime\n\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nlogger = CSVLogger(\"logs\", name=f\"metrics_{timestamp}\")\n\naug = K.AugmentationSequential(\n    K.RandomResizedCrop(size=(target_size, target_size), scale=(0.4, 1.0)),\n    K.RandomHorizontalFlip(),\n    K.RandomVerticalFlip(),\n    K.RandomGaussianBlur(kernel_size=(7,7), sigma=(0.1, 1.5), p=0.3),\n    K.RandomBrightness(brightness=(0.85, 1.15), p=0.5),\n    data_keys=['input'],\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"eaca9025-7baf-4800-987d-874f10d475e4","cell_type":"markdown","source":"### Helper Functions","metadata":{}},{"id":"3be0076f-cc92-4394-aea3-0a487f527762","cell_type":"code","source":"class SSLDataset(Dataset):\n    def __init__(self, scenes, bands, transforms=None):\n        \"\"\"\n        Args:\n            scenes (list): List of scene folder paths.\n            bands (list): List of band names (e.g., [\"B1\",\"B2\"]).\n            patch_size (tuple): Size of random crop (H, W).\n            transforms (callable, optional): Optional transform to apply to patches.\n        \"\"\"\n        self.scenes = scenes\n        self.bands = bands\n        # self.patch_size = patch_size\n        self.transforms = transforms\n        self.target_h= None\n        self.target_w = None\n        \n\n        # Precompute all timestamp paths to treat each timestamp as a sample\n        self.samples = []\n        for scene_path in scenes:\n            timestamps = sorted([\n                d for d in os.listdir(scene_path)\n                if os.path.isdir(os.path.join(scene_path, d))\n            ])\n            for ts in timestamps:\n                self.samples.append(os.path.join(scene_path, ts))\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        ts_path = self.samples[idx]\n\n        with rasterio.open(os.path.join(ts_path, \"B2.tif\")) as src:\n            target_h, target_w = src.height, src.width\n            # print(target_h,target_w, \"target width and height\" )\n\n        band_arrays = []\n\n        for b in self.bands:\n            path = os.path.join(ts_path, f\"{b}.tif\")\n            with rasterio.open(path) as src:\n                if src.height == target_h and src.width == target_w:\n                    arr = src.read(1).astype(np.float32)\n                else:\n                    arr = src.read(\n                        1,\n                        out_shape=(target_h, target_w),\n                        resampling=Resampling.bilinear\n                    ).astype(np.float32)\n\n            band_arrays.append(arr)\n\n        # Insert fake B10\n        insert_idx = 10\n        b10_pad = np.zeros((target_h, target_w), dtype=np.float32)\n        band_arrays.insert(insert_idx, b10_pad)\n\n        img = np.stack(band_arrays, axis=0)\n\n        # img_patch = self._random_crop(img)\n\n        patch_tensor = torch.tensor(img, dtype=torch.float32)\n\n        if self.transforms:\n            patch_tensor = self.transforms(patch_tensor)\n\n        return {\"image\": patch_tensor}\n\ndef calculate_stats(dataset, n_samples=500):\n    mean = 0\n    std = 0\n    total = len(dataset)\n    n = min(total, n_samples)\n\n    # Randomly choose n indices\n    np.random.seed(42)\n    indices = np.random.choice(total, size=n, replace=False)\n    count=0\n    for i in indices:\n        count=count+1\n        print(count)\n        sample = dataset[i]\n        img = sample[\"image\"]   # TorchGeo-style dictionary\n\n        mean += img.mean(dim=(1, 2))\n        std += img.std(dim=(1, 2))\n    mean /= n\n    std /= n\n    return mean, std\n\n\ndef summary_trainable(model):\n    table = PrettyTable()\n    table.field_names = [\"Module\", \"Type\", \"Trainable Params\", \"Total Params\"]\n\n    for name, module in model.named_children():\n        total_params = sum(p.numel() for p in module.parameters())\n        trainable_params = sum(p.numel() for p in module.parameters() if p.requires_grad)\n        table.add_row([name, type(module).__name__, f\"{trainable_params:,}\", f\"{total_params:,}\"])\n\n    total_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    total_params = sum(p.numel() for p in model.parameters())\n    \n    print(table)\n    print(f\"Total trainable parameters: {total_trainable:,} ({total_trainable / 1e6:.2f} M)\")\n    print(f\"Total parameters: {total_params:,} ({total_params / 1e6:.2f} M)\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"540591b6-1fcc-4d29-9ace-2b417131dbed","cell_type":"code","source":"# root_dir = \"data/s2a\"\nroot_dir = \"/kaggle/input/icpr-2026-competition-ssl-s2a-3k-subset/ICPR_SSL_S2A_3k_sample\"\n# List all folders\n# scenes = sorted(glob.glob(os.path.join(root_dir, \"*/\")))\nscenes= [\"/kaggle/input/icpr-2026-competition-ssl-s2a-3k-subset/ICPR_SSL_S2A_3k_sample/000017\",\"/kaggle/input/icpr-2026-competition-ssl-s2a-3k-subset/ICPR_SSL_S2A_3k_sample/000040\",\"/kaggle/input/icpr-2026-competition-ssl-s2a-3k-subset/ICPR_SSL_S2A_3k_sample/000058\",\"/kaggle/input/icpr-2026-competition-ssl-s2a-3k-subset/ICPR_SSL_S2A_3k_sample/000066\"]\n# scenes = [\"data/s2a/000015\", \"data/s2a/000016\"]  # list of scene folders\nbands = [\"B1\",\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B7\",\"B8\",\"B8A\",\"B9\",\"B11\",\"B12\"]\n# print(scenes)\n\n# import time\n# # One time run to get mean and std\n# temp_dataset = SSLDataset(scenes, bands)\n# start_time=time.time()\n# mean, std = calculate_stats(temp_dataset, n_samples=10000)\n# end_time=time.time()\n# print(f\"calculate_stats time: {(end_time-start_time)/60} min\")\n# print(mean)\n# print(std)\n\n# based on 10k samples\nmean= [1333.8029, 1488.1448, 1745.9066, 1985.6210, 2322.0129, 2837.1787,\n        3065.8462, 3192.4492, 3225.1826, 3344.8479,    0.0000, 2683.2991,\n        2116.8357]\nstd = [384.9683, 472.5244, 497.7275, 590.9384, 578.0192, 641.7764, 699.6282,\n        752.0769, 709.3992, 752.4539,   0.0000, 568.3574, 542.2833]\n\n# based on 500 sample\n# mean= [1041.5322, 1224.2570, 1549.6492, 1815.5840, 2171.1243, 2729.5166,\n#         2990.2266, 3074.2515, 3162.9661, 3260.7983,    0.0000, 2969.8357,\n#         2335.3250]\n# std = [328.5996, 410.0965, 443.5781, 547.2238, 519.4624, 547.1485, 606.4136,\n#         649.6067, 621.7164, 687.0721,   0.0000, 574.0366, 560.9932]\n\n# mean = [2358.7412, 2402.7629, 2580.9255, 2614.2227, 3057.6877, 3578.1008,\n#         3796.8345, 3795.6868, 3947.5913, 4833.6362,    0.0000, 3379.1743,\n#         2666.4465]\n# std = [2994.4861, 2847.0354, 2542.9307, 2411.1196, 2399.0249, 2137.6804,\n#         2036.8357, 2042.7140, 1957.9615, 3559.4121,    0.0000, 1535.7960,\n#         1393.8278]\n\n# to avoid 0 std\nstd = [max(s, 1e-5) for s in std]   \n\n# define transform\ntransform = transforms.Compose([\n    transforms.Resize((target_size, target_size)),\n    transforms.Normalize(mean=mean, std=std)\n])\n\ndataset = SSLDataset(scenes, bands, transforms=transform)\nprint(len(dataset))\nprint(dataset[0]['image'].shape)\n\ndata_loader = DataLoader(\n    dataset, \n    batch_size=target_batch_size, \n    shuffle=True, \n    pin_memory=True,\n    num_workers=target_num_workers,\n    worker_init_fn=lambda worker_id: np.random.seed(SEED + worker_id)\n)\nnum_batches = len(data_loader)\nprint(\"Number of batches:\", num_batches)\n\nimport time\ntask = MoCoTask(\n    model=\"resnet50\",      \n    weights= ResNet50_Weights.SENTINEL2_ALL_MOCO,\n    in_channels=13,       \n    version=2,             # MoCo v2\n    size=target_size,          \n    augmentation1=aug,\n    augmentation2=aug,\n    lr=1e-4,\n    memory_bank_size=2048,\n    temperature=0.15,\n)\n\n# # Load your checkpoint to resume task\n# ckpt_path = \"/kaggle/working/ssl_3k_ckpt_20260206_063623.ckpt\"\n# task = task.load_from_checkpoint(ckpt_path)\n\n# -----------------------------\n# PEFT / Full Fine-Tuning Logic\n# -----------------------------\nif use_peft:\n    print(\"Using PEFT: freezing backbone except last block, training projection head...\")\n    for name, param in task.backbone.named_parameters():\n        if \"layer4\" in name:      # optionally fine-tune last residual block\n            param.requires_grad = True\n        else:\n            param.requires_grad = False\nelse:\n    print(\"Full fine-tuning: backbone and projection head trainable...\")\n    for param in task.backbone.parameters():\n        param.requires_grad = True\n\n# Momentum backbone always frozen\nfor param in task.backbone_momentum.parameters():\n    param.requires_grad = False\n\n# Projection head always trainable\nfor param in task.projection_head.parameters():\n    param.requires_grad = True\n\n# Example usage for your task\nsummary_trainable(task)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"ec007d00-7925-4db4-b1e3-f90ad1d2f0fd","cell_type":"code","source":"trainer = Trainer(\n    max_epochs=target_max_epoch,\n    enable_progress_bar=True, \n    log_every_n_steps=num_batches,\n    precision=32,\n    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n    deterministic=True,\n    logger=logger)\n\nstart_time=time.time()\ntrainer.fit(task, data_loader)\nend_time=time.time()\nprint(f\"Training time: {(end_time-start_time)/60} min\")\n\nprint(task.trainer.logged_metrics)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"499f19ca-eb50-4e33-b265-37356d7c2e98","cell_type":"code","source":"# Save the backbone encoder only\ntorch.save(task.backbone.state_dict(),f\"ssl_backbone_{timestamp}.pth\")\ntorch.save(task.projection_head.state_dict(), f\"projection_head_{timestamp}.pth\")\ntrainer.save_checkpoint(f\"ssl_3k_ckpt_{timestamp}.ckpt\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}