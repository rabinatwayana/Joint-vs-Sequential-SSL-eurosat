{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1663377,"sourceType":"datasetVersion","datasetId":918039}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"e0cb307d","cell_type":"markdown","source":"## Self Supervised Learning (SSL)","metadata":{}},{"id":"3266bf3c","cell_type":"code","source":"!pip install torchgeo --quiet\n!pip install lightning --quiet\n!pip install prettytable","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T20:40:05.627036Z","iopub.execute_input":"2026-02-12T20:40:05.627238Z","iopub.status.idle":"2026-02-12T20:40:20.971123Z","shell.execute_reply.started":"2026-02-12T20:40:05.627217Z","shell.execute_reply":"2026-02-12T20:40:20.970503Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m652.1/652.1 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.1/246.1 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m859.3/859.3 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m853.6/853.6 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.6/165.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.5/760.5 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: prettytable in /usr/local/lib/python3.12/dist-packages (3.16.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prettytable) (0.2.14)\n","output_type":"stream"}],"execution_count":1},{"id":"fce313a0","cell_type":"code","source":"import os\nSEED = 42\n# Environment variables\nos.environ[\"PYTHONHASHSEED\"] = str(SEED)\n# os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T21:14:42.979626Z","iopub.execute_input":"2026-02-12T21:14:42.979904Z","iopub.status.idle":"2026-02-12T21:14:42.983852Z","shell.execute_reply.started":"2026-02-12T21:14:42.979876Z","shell.execute_reply":"2026-02-12T21:14:42.983010Z"}},"outputs":[],"execution_count":2},{"id":"c72eb59f-1500-4e39-b46c-556d5a33e05f","cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\n# os.cpu_count()\ntorch.cuda.is_available()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T21:14:48.407589Z","iopub.execute_input":"2026-02-12T21:14:48.407827Z","iopub.status.idle":"2026-02-12T21:14:51.660257Z","shell.execute_reply.started":"2026-02-12T21:14:48.407808Z","shell.execute_reply":"2026-02-12T21:14:51.659495Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}],"execution_count":3},{"id":"90794fb4-bc3f-48cf-a840-cbe31a22fcd7","cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nimport rasterio\nimport numpy as np\nfrom rasterio.enums import Resampling\nimport torch.nn as nn\nimport pytorch_lightning as pl\nfrom torchvision.models import resnet50\nfrom torch.utils.data import DataLoader\nfrom lightning.pytorch import Trainer\nfrom torchvision import transforms  \nfrom torchgeo.trainers.moco import MoCoTask\nfrom torchgeo.models import ResNet50_Weights\nimport kornia.augmentation as K\nimport torch.nn.functional as F\nimport torchgeo.transforms as T\nfrom lightning.pytorch.loggers import CSVLogger\nimport glob\nimport shutil\nimport random\nimport time\nfrom prettytable import PrettyTable","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T21:14:55.238240Z","iopub.execute_input":"2026-02-12T21:14:55.238926Z","iopub.status.idle":"2026-02-12T21:15:10.529818Z","shell.execute_reply.started":"2026-02-12T21:14:55.238902Z","shell.execute_reply":"2026-02-12T21:15:10.528944Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":4},{"id":"af5f7783-8984-445f-86c3-c0d095d433fe","cell_type":"code","source":"random.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\npl.seed_everything(SEED, workers=True)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.use_deterministic_algorithms(True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T21:15:10.530936Z","iopub.execute_input":"2026-02-12T21:15:10.531275Z","iopub.status.idle":"2026-02-12T21:15:10.542766Z","shell.execute_reply.started":"2026-02-12T21:15:10.531245Z","shell.execute_reply":"2026-02-12T21:15:10.542027Z"}},"outputs":[{"name":"stderr","text":"Seed set to 42\n","output_type":"stream"}],"execution_count":5},{"id":"795ed230-3932-4ff3-bb39-e13f7b081e2a","cell_type":"code","source":"import os\nimport pandas as pd\n\n# --- CONFIG ---\nroot_dir = \"/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT\"  # folder with all images\ncsv_output = \"/kaggle/working/eurosat.csv\"\n\n# Optional: dictionary mapping image filenames to labels\n# If your filenames encode labels, you can skip this and extract label from filename\n# labels_dict = {\n#     \"img_00001.jpg\": \"Forest\",\n#     \"img_00002.jpg\": \"AnnualCrop\",\n#     # ...\n# }\n\n\n# --- COLLECT IMAGE INFO ---\ndata=[]\n# Iterate over each class folder\nfor class_name in os.listdir(root_dir):\n    class_path = os.path.join(root_dir, class_name)\n    print(class_path)\n    if not os.path.isdir(class_path):\n        continue  # skip files in root_dir\n\n    # Iterate over images in the class folder\n    for fname in os.listdir(class_path):\n        if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n            path = os.path.join(class_path, fname)\n            \n            data.append({\n                \"id\": os.path.splitext(fname)[0].split(\"_\")[-1],\n                 \"fname\": fname,\n                \"path\": path,\n                \"label\": class_name\n            })\n    \n\n# --- CREATE DATAFRAME ---\ndf = pd.DataFrame(data)\n\n\n# --- TASK SPLIT: 80% SSL, 20% Downstream ---\nsplit_idx = int(0.8 * len(df))\ndf['task'] = 'ssl'  # default\ndf.loc[split_idx:, 'task'] = 'downstream'\n\n# --- SSL SPLIT: 25% each subst1,2,3,4 ---\nssl_df = df[df['task'] == 'ssl'].copy()\nn_ssl = len(ssl_df)\nssl_subst_indices = np.array_split(np.arange(n_ssl), 4)  # 4 splits\n\nssl_split_names = ['subst1', 'subst2', 'subst3', 'subst4']\nssl_splits = np.empty(n_ssl, dtype=object)\n\nfor i, idx in enumerate(ssl_subst_indices):\n    ssl_splits[idx] = ssl_split_names[i]\n\ndf.loc[df['task'] == 'ssl', 'split'] = ssl_splits\n\n# --- Downstream SPLIT: train 70%, val 15%, test 15% ---\ndown_df = df[df['task'] == 'downstream'].copy()\nn_down = len(down_df)\n\ntrain_end = int(0.7 * n_down)\nval_end = int(0.85 * n_down)  # 70% + 15%\n\ndown_splits = ['train'] * train_end + ['val'] * (val_end - train_end) + ['test'] * (n_down - val_end)\ndf.loc[df['task'] == 'downstream', 'split'] = down_splits\n\n# --- FINAL CHECK ---\nprint(df['task'].value_counts())\nprint(df['split'].value_counts())\nprint(df.head(10))\n\n\n\n# Optional: shuffle rows\n# df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n# print(df)\n# --- SAVE CSV ---\n# df.to_csv(csv_output, index=False)\n# print(f\"CSV saved to {csv_output}\")\n# print(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T22:59:36.471788Z","iopub.execute_input":"2026-02-12T22:59:36.472520Z","iopub.status.idle":"2026-02-12T22:59:36.591571Z","shell.execute_reply.started":"2026-02-12T22:59:36.472492Z","shell.execute_reply":"2026-02-12T22:59:36.590951Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/SeaLake\n/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/Highway\n/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/River\n/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/Pasture\n/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/Industrial\n/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/Residential\n/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/PermanentCrop\n/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/validation.csv\n/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/AnnualCrop\n/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/train.csv\n/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/test.csv\n/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/label_map.json\n/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/Forest\n/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSAT/HerbaceousVegetation\ntask\nssl           21600\ndownstream     5400\nName: count, dtype: int64\nsplit\nsubst1    5400\nsubst2    5400\nsubst3    5400\nsubst4    5400\ntrain     3779\nval        811\ntest       810\nName: count, dtype: int64\n     id             fname                                               path  \\\n0  2025  SeaLake_2025.jpg  /kaggle/input/datasets/apollo2506/eurosat-data...   \n1  1571  SeaLake_1571.jpg  /kaggle/input/datasets/apollo2506/eurosat-data...   \n2   227   SeaLake_227.jpg  /kaggle/input/datasets/apollo2506/eurosat-data...   \n3   926   SeaLake_926.jpg  /kaggle/input/datasets/apollo2506/eurosat-data...   \n4   907   SeaLake_907.jpg  /kaggle/input/datasets/apollo2506/eurosat-data...   \n5   528   SeaLake_528.jpg  /kaggle/input/datasets/apollo2506/eurosat-data...   \n6   844   SeaLake_844.jpg  /kaggle/input/datasets/apollo2506/eurosat-data...   \n7   830   SeaLake_830.jpg  /kaggle/input/datasets/apollo2506/eurosat-data...   \n8  2215  SeaLake_2215.jpg  /kaggle/input/datasets/apollo2506/eurosat-data...   \n9  1203  SeaLake_1203.jpg  /kaggle/input/datasets/apollo2506/eurosat-data...   \n\n     label task   split  \n0  SeaLake  ssl  subst1  \n1  SeaLake  ssl  subst1  \n2  SeaLake  ssl  subst1  \n3  SeaLake  ssl  subst1  \n4  SeaLake  ssl  subst1  \n5  SeaLake  ssl  subst1  \n6  SeaLake  ssl  subst1  \n7  SeaLake  ssl  subst1  \n8  SeaLake  ssl  subst1  \n9  SeaLake  ssl  subst1  \n","output_type":"stream"}],"execution_count":16},{"id":"890b261c-7189-4b2b-9c11-4324424c958a","cell_type":"code","source":"class SSLDataset(Dataset):\n    def __init__(self, scenes, bands, transforms=None):\n        \"\"\"\n        Args:\n            scenes (list): List of scene folder paths.\n            bands (list): List of band names (e.g., [\"B1\",\"B2\"]).\n            patch_size (tuple): Size of random crop (H, W).\n            transforms (callable, optional): Optional transform to apply to patches.\n        \"\"\"\n        self.scenes = scenes\n        self.bands = bands\n        # self.patch_size = patch_size\n        self.transforms = transforms\n        self.target_h= None\n        self.target_w = None\n        \n\n        # Precompute all timestamp paths to treat each timestamp as a sample\n        self.samples = []\n        for scene_path in scenes:\n            timestamps = sorted([\n                d for d in os.listdir(scene_path)\n                if os.path.isdir(os.path.join(scene_path, d))\n            ])\n            for ts in timestamps:\n                self.samples.append(os.path.join(scene_path, ts))\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        ts_path = self.samples[idx]\n\n        with rasterio.open(os.path.join(ts_path, \"B2.tif\")) as src:\n            target_h, target_w = src.height, src.width\n            # print(target_h,target_w, \"target width and height\" )\n\n        band_arrays = []\n\n        for b in self.bands:\n            path = os.path.join(ts_path, f\"{b}.tif\")\n            with rasterio.open(path) as src:\n                if src.height == target_h and src.width == target_w:\n                    arr = src.read(1).astype(np.float32)\n                else:\n                    arr = src.read(\n                        1,\n                        out_shape=(target_h, target_w),\n                        resampling=Resampling.bilinear\n                    ).astype(np.float32)\n\n            band_arrays.append(arr)\n\n        # Insert fake B10\n        insert_idx = 10\n        b10_pad = np.zeros((target_h, target_w), dtype=np.float32)\n        band_arrays.insert(insert_idx, b10_pad)\n\n        img = np.stack(band_arrays, axis=0)\n\n        # img_patch = self._random_crop(img)\n\n        patch_tensor = torch.tensor(img, dtype=torch.float32)\n\n        if self.transforms:\n            patch_tensor = self.transforms(patch_tensor)\n\n        return {\"image\": patch_tensor}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"0d972eb3-7c40-4ba8-9d4d-52f5ca7e243b","cell_type":"code","source":"from torchgeo.datasets import EuroSAT\n\ndataset= EuroSAT(root='/kaggle/input/datasets/apollo2506/eurosat-dataset/')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T21:30:48.039676Z","iopub.execute_input":"2026-02-12T21:30:48.039932Z","iopub.status.idle":"2026-02-12T21:30:48.048860Z","shell.execute_reply.started":"2026-02-12T21:30:48.039908Z","shell.execute_reply":"2026-02-12T21:30:48.048029Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mDatasetNotFoundError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/1705812584.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchgeo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEuroSAT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mEuroSAT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/kaggle/input/datasets/apollo2506/eurosat-dataset/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchgeo/datasets/eurosat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, split, bands, transforms, download, checksum)\u001b[0m\n\u001b[1;32m    146\u001b[0m         ).long()\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mvalid_fns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchgeo/datasets/eurosat.py\u001b[0m in \u001b[0;36m_verify\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 )\n\u001b[1;32m    194\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mDatasetNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# Check image directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mDatasetNotFoundError\u001b[0m: Dataset not found in `root='/kaggle/input/datasets/apollo2506/eurosat-dataset/'` and `download=False`, either specify a different `root` or use `download=True` to automatically download the dataset."],"ename":"DatasetNotFoundError","evalue":"Dataset not found in `root='/kaggle/input/datasets/apollo2506/eurosat-dataset/'` and `download=False`, either specify a different `root` or use `download=True` to automatically download the dataset.","output_type":"error"}],"execution_count":9},{"id":"ac249289-34f6-466f-805f-de6a073212ea","cell_type":"code","source":"\nSub-sample 3k Data\n\n# root_dir = \"/Volumes/WD_Rabina/competition/extracted_data/s2a\"\n# # List all folders\n# scenes = sorted(glob.glob(os.path.join(root_dir, \"*/\")))\n# # print(scenes)\n# print(len(scenes))\n\n# no_of_files=3000\n\n# # Randomly select 3000 scenes (without replacement)\n# selected_scenes = random.sample(scenes, k=3000)\n\n# print(f\"Total selected scenes: {len(selected_scenes)}\")\n# # print(selected_scenes[:10])  # show first 10 for sanity check\n\n# # Path to new folder where selected scenes will be copied\n# destination_root = \"data/s2a_3k_sample\"\n# os.makedirs(destination_root, exist_ok=True)  # create folder if it doesn't exist\n\n# # Copy each selected folder\n# count=0\n# for scene_path in selected_scenes:\n#     # Get folder name only (e.g., \"000015\")\n#     folder_name = os.path.basename(os.path.normpath(scene_path))\n    \n#     # Destination path\n#     dest_path = os.path.join(destination_root, folder_name)\n#     count=count+1\n#     print(count)\n#     # Copy folder and all its contents\n#     shutil.copytree(scene_path, dest_path)\n\n# print(f\"Copied {len(selected_scenes)} folders to {destination_root}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"ddf46e52-f888-4f43-a96a-b01575896bad","cell_type":"markdown","source":"### Settings","metadata":{}},{"id":"b1524f2e-eafe-4421-8fc2-bf32635eda5c","cell_type":"code","source":"target_size = 224\ntarget_batch_size= 8 #128 #prefer 256 or 128\ntarget_num_workers=4\ntarget_max_epoch=6\nuse_peft = True  \nfrom datetime import datetime\n\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nlogger = CSVLogger(\"logs\", name=f\"metrics_{timestamp}\")\n\naug = K.AugmentationSequential(\n    K.RandomResizedCrop(size=(target_size, target_size), scale=(0.4, 1.0)),\n    K.RandomHorizontalFlip(),\n    K.RandomVerticalFlip(),\n    K.RandomGaussianBlur(kernel_size=(7,7), sigma=(0.1, 1.5), p=0.3),\n    K.RandomBrightness(brightness=(0.85, 1.15), p=0.5),\n    data_keys=['input'],\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"eaca9025-7baf-4800-987d-874f10d475e4","cell_type":"markdown","source":"### Helper Functions","metadata":{}},{"id":"3be0076f-cc92-4394-aea3-0a487f527762","cell_type":"code","source":"class SSLDataset(Dataset):\n    def __init__(self, scenes, bands, transforms=None):\n        \"\"\"\n        Args:\n            scenes (list): List of scene folder paths.\n            bands (list): List of band names (e.g., [\"B1\",\"B2\"]).\n            patch_size (tuple): Size of random crop (H, W).\n            transforms (callable, optional): Optional transform to apply to patches.\n        \"\"\"\n        self.scenes = scenes\n        self.bands = bands\n        # self.patch_size = patch_size\n        self.transforms = transforms\n        self.target_h= None\n        self.target_w = None\n        \n\n        # Precompute all timestamp paths to treat each timestamp as a sample\n        self.samples = []\n        for scene_path in scenes:\n            timestamps = sorted([\n                d for d in os.listdir(scene_path)\n                if os.path.isdir(os.path.join(scene_path, d))\n            ])\n            for ts in timestamps:\n                self.samples.append(os.path.join(scene_path, ts))\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        ts_path = self.samples[idx]\n\n        with rasterio.open(os.path.join(ts_path, \"B2.tif\")) as src:\n            target_h, target_w = src.height, src.width\n            # print(target_h,target_w, \"target width and height\" )\n\n        band_arrays = []\n\n        for b in self.bands:\n            path = os.path.join(ts_path, f\"{b}.tif\")\n            with rasterio.open(path) as src:\n                if src.height == target_h and src.width == target_w:\n                    arr = src.read(1).astype(np.float32)\n                else:\n                    arr = src.read(\n                        1,\n                        out_shape=(target_h, target_w),\n                        resampling=Resampling.bilinear\n                    ).astype(np.float32)\n\n            band_arrays.append(arr)\n\n        # Insert fake B10\n        insert_idx = 10\n        b10_pad = np.zeros((target_h, target_w), dtype=np.float32)\n        band_arrays.insert(insert_idx, b10_pad)\n\n        img = np.stack(band_arrays, axis=0)\n\n        # img_patch = self._random_crop(img)\n\n        patch_tensor = torch.tensor(img, dtype=torch.float32)\n\n        if self.transforms:\n            patch_tensor = self.transforms(patch_tensor)\n\n        return {\"image\": patch_tensor}\n\ndef calculate_stats(dataset, n_samples=500):\n    mean = 0\n    std = 0\n    total = len(dataset)\n    n = min(total, n_samples)\n\n    # Randomly choose n indices\n    np.random.seed(42)\n    indices = np.random.choice(total, size=n, replace=False)\n    count=0\n    for i in indices:\n        count=count+1\n        print(count)\n        sample = dataset[i]\n        img = sample[\"image\"]   # TorchGeo-style dictionary\n\n        mean += img.mean(dim=(1, 2))\n        std += img.std(dim=(1, 2))\n    mean /= n\n    std /= n\n    return mean, std\n\n\ndef summary_trainable(model):\n    table = PrettyTable()\n    table.field_names = [\"Module\", \"Type\", \"Trainable Params\", \"Total Params\"]\n\n    for name, module in model.named_children():\n        total_params = sum(p.numel() for p in module.parameters())\n        trainable_params = sum(p.numel() for p in module.parameters() if p.requires_grad)\n        table.add_row([name, type(module).__name__, f\"{trainable_params:,}\", f\"{total_params:,}\"])\n\n    total_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    total_params = sum(p.numel() for p in model.parameters())\n    \n    print(table)\n    print(f\"Total trainable parameters: {total_trainable:,} ({total_trainable / 1e6:.2f} M)\")\n    print(f\"Total parameters: {total_params:,} ({total_params / 1e6:.2f} M)\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"540591b6-1fcc-4d29-9ace-2b417131dbed","cell_type":"code","source":"# root_dir = \"data/s2a\"\nroot_dir = \"/kaggle/input/icpr-2026-competition-ssl-s2a-3k-subset/ICPR_SSL_S2A_3k_sample\"\n# List all folders\n# scenes = sorted(glob.glob(os.path.join(root_dir, \"*/\")))\nscenes= [\"/kaggle/input/icpr-2026-competition-ssl-s2a-3k-subset/ICPR_SSL_S2A_3k_sample/000017\",\"/kaggle/input/icpr-2026-competition-ssl-s2a-3k-subset/ICPR_SSL_S2A_3k_sample/000040\",\"/kaggle/input/icpr-2026-competition-ssl-s2a-3k-subset/ICPR_SSL_S2A_3k_sample/000058\",\"/kaggle/input/icpr-2026-competition-ssl-s2a-3k-subset/ICPR_SSL_S2A_3k_sample/000066\"]\n# scenes = [\"data/s2a/000015\", \"data/s2a/000016\"]  # list of scene folders\nbands = [\"B1\",\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B7\",\"B8\",\"B8A\",\"B9\",\"B11\",\"B12\"]\n# print(scenes)\n\n# import time\n# # One time run to get mean and std\n# temp_dataset = SSLDataset(scenes, bands)\n# start_time=time.time()\n# mean, std = calculate_stats(temp_dataset, n_samples=10000)\n# end_time=time.time()\n# print(f\"calculate_stats time: {(end_time-start_time)/60} min\")\n# print(mean)\n# print(std)\n\n# based on 10k samples\nmean= [1333.8029, 1488.1448, 1745.9066, 1985.6210, 2322.0129, 2837.1787,\n        3065.8462, 3192.4492, 3225.1826, 3344.8479,    0.0000, 2683.2991,\n        2116.8357]\nstd = [384.9683, 472.5244, 497.7275, 590.9384, 578.0192, 641.7764, 699.6282,\n        752.0769, 709.3992, 752.4539,   0.0000, 568.3574, 542.2833]\n\n# based on 500 sample\n# mean= [1041.5322, 1224.2570, 1549.6492, 1815.5840, 2171.1243, 2729.5166,\n#         2990.2266, 3074.2515, 3162.9661, 3260.7983,    0.0000, 2969.8357,\n#         2335.3250]\n# std = [328.5996, 410.0965, 443.5781, 547.2238, 519.4624, 547.1485, 606.4136,\n#         649.6067, 621.7164, 687.0721,   0.0000, 574.0366, 560.9932]\n\n# mean = [2358.7412, 2402.7629, 2580.9255, 2614.2227, 3057.6877, 3578.1008,\n#         3796.8345, 3795.6868, 3947.5913, 4833.6362,    0.0000, 3379.1743,\n#         2666.4465]\n# std = [2994.4861, 2847.0354, 2542.9307, 2411.1196, 2399.0249, 2137.6804,\n#         2036.8357, 2042.7140, 1957.9615, 3559.4121,    0.0000, 1535.7960,\n#         1393.8278]\n\n# to avoid 0 std\nstd = [max(s, 1e-5) for s in std]   \n\n# define transform\ntransform = transforms.Compose([\n    transforms.Resize((target_size, target_size)),\n    transforms.Normalize(mean=mean, std=std)\n])\n\ndataset = SSLDataset(scenes, bands, transforms=transform)\nprint(len(dataset))\nprint(dataset[0]['image'].shape)\n\ndata_loader = DataLoader(\n    dataset, \n    batch_size=target_batch_size, \n    shuffle=True, \n    pin_memory=True,\n    num_workers=target_num_workers,\n    worker_init_fn=lambda worker_id: np.random.seed(SEED + worker_id)\n)\nnum_batches = len(data_loader)\nprint(\"Number of batches:\", num_batches)\n\nimport time\ntask = MoCoTask(\n    model=\"resnet50\",      \n    weights= ResNet50_Weights.SENTINEL2_ALL_MOCO,\n    in_channels=13,       \n    version=2,             # MoCo v2\n    size=target_size,          \n    augmentation1=aug,\n    augmentation2=aug,\n    lr=1e-4,\n    memory_bank_size=2048,\n    temperature=0.15,\n)\n\n# # Load your checkpoint to resume task\n# ckpt_path = \"/kaggle/working/ssl_3k_ckpt_20260206_063623.ckpt\"\n# task = task.load_from_checkpoint(ckpt_path)\n\n# -----------------------------\n# PEFT / Full Fine-Tuning Logic\n# -----------------------------\nif use_peft:\n    print(\"Using PEFT: freezing backbone except last block, training projection head...\")\n    for name, param in task.backbone.named_parameters():\n        if \"layer4\" in name:      # optionally fine-tune last residual block\n            param.requires_grad = True\n        else:\n            param.requires_grad = False\nelse:\n    print(\"Full fine-tuning: backbone and projection head trainable...\")\n    for param in task.backbone.parameters():\n        param.requires_grad = True\n\n# Momentum backbone always frozen\nfor param in task.backbone_momentum.parameters():\n    param.requires_grad = False\n\n# Projection head always trainable\nfor param in task.projection_head.parameters():\n    param.requires_grad = True\n\n# Example usage for your task\nsummary_trainable(task)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"ec007d00-7925-4db4-b1e3-f90ad1d2f0fd","cell_type":"code","source":"trainer = Trainer(\n    max_epochs=target_max_epoch,\n    enable_progress_bar=True, \n    log_every_n_steps=num_batches,\n    precision=32,\n    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n    deterministic=True,\n    logger=logger)\n\nstart_time=time.time()\ntrainer.fit(task, data_loader)\nend_time=time.time()\nprint(f\"Training time: {(end_time-start_time)/60} min\")\n\nprint(task.trainer.logged_metrics)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"499f19ca-eb50-4e33-b265-37356d7c2e98","cell_type":"code","source":"# Save the backbone encoder only\ntorch.save(task.backbone.state_dict(),f\"ssl_backbone_{timestamp}.pth\")\ntorch.save(task.projection_head.state_dict(), f\"projection_head_{timestamp}.pth\")\ntrainer.save_checkpoint(f\"ssl_3k_ckpt_{timestamp}.ckpt\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}