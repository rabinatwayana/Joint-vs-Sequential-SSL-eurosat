{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1663377,"sourceType":"datasetVersion","datasetId":918039}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"e0cb307d","cell_type":"markdown","source":"## Self Supervised Learning (SSL)","metadata":{}},{"id":"3266bf3c","cell_type":"code","source":"!pip install torchgeo --quiet\n!pip install lightning --quiet\n!pip install prettytable","metadata":{"execution":{"iopub.status.busy":"2026-02-15T13:03:46.256773Z","iopub.execute_input":"2026-02-15T13:03:46.257414Z","iopub.status.idle":"2026-02-15T13:04:00.362579Z","shell.execute_reply.started":"2026-02-15T13:03:46.257374Z","shell.execute_reply":"2026-02-15T13:04:00.361325Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: prettytable in /usr/local/lib/python3.12/dist-packages (3.16.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prettytable) (0.2.14)\n","output_type":"stream"}],"execution_count":4},{"id":"33810484-8aae-4ffa-870c-9e59c2596d4b","cell_type":"code","source":"import rasterio\n\n# Path to your image\nimg_path = \"/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSATallBands/AnnualCrop/AnnualCrop_1.tif\"\n\n# Open the TIFF\nwith rasterio.open(img_path) as src:\n    print(f\"Number of bands: {src.count}\")\n    print(f\"Width: {src.width}, Height: {src.height}\")\n    \n    # Iterate over bands\n    for i in range(1, src.count + 1):  # rasterio bands are 1-indexed\n        band = src.read(i)\n        print(f\"Band {i} shape: {band.shape}, dtype: {band.dtype}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T13:04:00.365196Z","iopub.execute_input":"2026-02-15T13:04:00.365495Z","iopub.status.idle":"2026-02-15T13:04:00.391739Z","shell.execute_reply.started":"2026-02-15T13:04:00.365465Z","shell.execute_reply":"2026-02-15T13:04:00.390159Z"}},"outputs":[{"name":"stdout","text":"Number of bands: 13\nWidth: 64, Height: 64\nBand 1 shape: (64, 64), dtype: uint16\nBand 2 shape: (64, 64), dtype: uint16\nBand 3 shape: (64, 64), dtype: uint16\nBand 4 shape: (64, 64), dtype: uint16\nBand 5 shape: (64, 64), dtype: uint16\nBand 6 shape: (64, 64), dtype: uint16\nBand 7 shape: (64, 64), dtype: uint16\nBand 8 shape: (64, 64), dtype: uint16\nBand 9 shape: (64, 64), dtype: uint16\nBand 10 shape: (64, 64), dtype: uint16\nBand 11 shape: (64, 64), dtype: uint16\nBand 12 shape: (64, 64), dtype: uint16\nBand 13 shape: (64, 64), dtype: uint16\n","output_type":"stream"}],"execution_count":5},{"id":"d402297f-2f9f-42ec-97b7-724625cc92c4","cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\n\n# ========================\n# Imports\n# ========================\nimport os\nimport random\nfrom datetime import datetime\nimport glob\nimport argparse\n\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, Subset\nimport rasterio\nfrom rasterio.enums import Resampling\nfrom prettytable import PrettyTable\nfrom lightning.pytorch.loggers import CSVLogger\nfrom torchvision import transforms\nfrom lightning.pytorch import Trainer\nimport kornia.augmentation as K\nfrom dataclasses import dataclass\nfrom torchgeo.trainers.moco import MoCoTask\nfrom torchgeo.models.resnet import ResNet18_Weights\nimport pytorch_lightning as pl\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nimport pandas as pd\nfrom lightning.pytorch.callbacks import ModelCheckpoint\nimport time\n\n# ========================\n# Reproducibility\n# ========================\nseed = 42\nos.environ[\"PYTHONHASHSEED\"] = str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\nimport pytorch_lightning as pl\npl.seed_everything(seed, workers=True)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.use_deterministic_algorithms(True)\n\n# Timestamp for logging / checkpoints\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\ndef seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n\ng = torch.Generator()\ng.manual_seed(seed)\n\n@dataclass\nclass DataConfig:\n    data_root_dir: str = \"/home/krschap/rabina/data/s2a\"\n    split_path: str = \"eurosat_all_bands_split.csv\"\n    stats_split: str = \"full_ssl\"  # options: full_ssl, subset1, subset2, subset3, subset4\n    split: str = \"subset1\"\n    compute_stats: bool = True\n    # n_samples: int = None\n    batch_size: int = 64\n    patch_size: int = 264\n    num_workers: int = 1\n\n@dataclass\nclass TrainingConfig:\n    experiment_out_dir: str = f\"ssl_moco_{timestamp}\"\n    model: str = \"resnet18\"\n    in_channels: int = 13\n    version: int = 2\n    lr: float = 1e-4\n    use_peft: bool = False\n    temperature: float = 0.15\n    memory_bank_size: int = 2048\n    target_size: int = 224\n    max_epochs: int = 100\n    batch_size: int =32\n    #devices = []\n\ndef split_dataset(root_dir,csv_output):\n    # --- COLLECT IMAGE INFO ---\n    data=[]\n    # Iterate over each class folder\n    for class_name in os.listdir(root_dir):\n        class_path = os.path.join(root_dir, class_name)\n        # print(class_path)\n        if not os.path.isdir(class_path):\n            continue  # skip files in root_dir\n    \n        # Iterate over images in the class folder\n        for fname in os.listdir(class_path):\n            # if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n            if fname.lower().endswith((\".tif\", \".tiff\")):\n                # path = os.path.join(class_path, fname)\n                rel_path = os.path.join(class_name, fname)\n                data.append({\n                    \"id\": os.path.splitext(fname)[0].split(\"_\")[-1],\n                     \"fname\": fname,\n                    \"rel_path\": rel_path,\n                    \"label\": class_name\n                })\n    # --- CREATE DATAFRAME ---\n    df = pd.DataFrame(data)\n    # print(df.columns)\n    # --- STRATIFIED SPLIT: 80% SSL, 20% Downstream ---\n    ssl_df, downstream_df = train_test_split(\n        df,\n        test_size=0.2,\n        stratify=df['label'],\n        random_state=42\n    )\n    \n    ssl_df['task'] = 'ssl'\n    downstream_df['task'] = 'downstream'\n    \n    df = pd.concat([ssl_df, downstream_df]).reset_index(drop=True)\n    \n    ssl_df = df[df['task'] == 'ssl'].copy()\n    \n    skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n    \n    ssl_splits = np.empty(len(ssl_df), dtype=object)\n    split_names = ['subset1', 'subset2', 'subset3', 'subset4']\n    \n    for fold_idx, (_, val_idx) in enumerate(skf.split(ssl_df, ssl_df['label'])):\n        ssl_splits[val_idx] = split_names[fold_idx]\n    \n    df.loc[ssl_df.index, 'split'] = ssl_splits\n    \n    down_df = df[df['task'] == 'downstream'].copy()\n    # Step 1: Train (70%) vs Temp (30%)\n    train_df, temp_df = train_test_split(\n        down_df,\n        test_size=0.30,\n        stratify=down_df['label'],\n        random_state=42\n    )\n    # Step 2: Temp â†’ Val (15%) + Test (15%)\n    val_df, test_df = train_test_split(\n        temp_df,\n        test_size=0.50,  # half of 30% = 15%\n        stratify=temp_df['label'],\n        random_state=42\n    )\n    # Assign splits back\n    df.loc[train_df.index, 'split'] = 'train'\n    df.loc[val_df.index, 'split'] = 'val'\n    df.loc[test_df.index, 'split'] = 'test'\n    \n    # --- FINAL CHECK ---\n    print(df['task'].value_counts())\n    print(df['split'].value_counts())\n    # print(df.head(10))\n    \n    # --- SAVE CSV ---\n    df.to_csv(csv_output, index=False)\n    print(f\"CSV saved to {csv_output}\")\n\nclass SSLDataset(Dataset):\n    def __init__(self, data_dir, split_path, split, transforms=None):\n        \"\"\"\n        Args:\n            data_dir (str): Eurosat folder paths.\n            split_path (str): CSV file path containing splits metadata\n            split (str): all, full_ssl, subset1, subset2, subset3, subset4, train, test, val\n            transforms (callable, optional): Optional transform to apply to patches.\n        \"\"\"\n        self.data_dir = data_dir\n        self.split_path = split_path\n        self.transforms = transforms\n        \n        # Precompute all paths based on split\n        self.samples = []\n        df=pd.read_csv(split_path)\n        # if split==\"all\":\n        #     pass\n        if split==\"full_ssl\":\n            df=df[df['task'] == \"ssl\"]\n        else:\n            df=df[df['split'] == split]\n        self.samples = df['rel_path'].tolist()\n        \n\n    def __len__(self):\n        return len(self.samples)\n    \n\n    # def __getitem__(self, idx):\n    #     sample_path = os.path.join(self.data_dir, self.samples[idx])\n        \n    #     with Image.open(sample_path) as img:\n    #         patch_tensor = img.convert(\"RGB\")\n    #     if self.transforms:\n    #         patch_tensor = self.transforms(patch_tensor)\n\n    #     return {\"image\": patch_tensor}\n    def __getitem__(self, idx):\n        sample_path = os.path.join(self.data_dir, self.samples[idx])\n    \n        # --- Read TIFF with rasterio ---\n        with rasterio.open(sample_path) as src:\n            # Read all bands as float32\n            bands = [src.read(b).astype(np.float32) for b in range(1, src.count + 1)]\n        \n        # Stack bands to shape [C, H, W]\n        img_array = np.stack(bands, axis=0)\n    \n        # --- Convert to torch tensor ---\n        patch_tensor = torch.tensor(img_array, dtype=torch.float32)\n    \n        # --- Apply transforms if provided ---\n        if self.transforms:\n            patch_tensor = self.transforms(patch_tensor)\n    \n        return {\"image\": patch_tensor}\n\ndef calculate_stats_parallel(dataset, batch_size=16, num_workers=4):\n\n    n_samples = len(dataset)\n    print(f\"Total samples in dataset: {n_samples}\")\n\n    # if n_samples is not None:\n    #     n = min(total, n_samples)\n    #     print(f\"Calculating stats on {n} randomly selected samples...\")\n    #     # Randomly select a subset of indices for efficiency\n    #     np.random.seed(seed)\n    #     indices = np.random.choice(total, size=n, replace=False)\n    #     subset = Subset(dataset, indices)\n    # else:\n    print(f\"Calculating stats on the entire dataset...\")\n    # subset = dataset\n    # n_samples=total\n\n    loader = DataLoader(\n        dataset,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=num_workers,\n        worker_init_fn=seed_worker,\n        generator=g\n    )\n\n    channel_sum = 0.0\n    channel_sum_sq = 0.0\n    num_pixels = 0\n\n    total_batches = len(loader)\n    print(f\"Total batches to process: {total_batches}\")\n    for batch_idx, batch in enumerate(loader, start=1):\n        imgs = batch[\"image\"]\n        b, c, h, w = imgs.shape\n        channel_sum += imgs.sum(dim=(0, 2, 3))\n        channel_sum_sq += (imgs**2).sum(dim=(0, 2, 3))\n        num_pixels += b * h * w\n\n        if batch_idx % 100 == 0 or batch_idx == total_batches:\n            print(f\"Processed batch {batch_idx}/{total_batches} \")\n                # f\"â‰ˆ {batch_idx * b}/{n_samples} samples\")\n\n    mean = channel_sum / num_pixels\n    torch.set_printoptions(sci_mode=False, precision=4)\n    # std  = torch.sqrt(channel_sum_sq / num_pixels - mean**2)\n    variance = channel_sum_sq / num_pixels - mean**2\n    variance = torch.clamp(variance, min=0)  # Avoid negative values\n    # Add small epsilon to avoid sqrt(0) issues\n    std = torch.sqrt(variance + 1e-8)\n    return mean, std\n\ndef summary_trainable(model):\n    table = PrettyTable()\n    table.field_names = [\"Module\", \"Type\", \"Trainable Params\", \"Total Params\"]\n\n    for name, module in model.named_children():\n        total_params = sum(p.numel() for p in module.parameters())\n        trainable_params = sum(p.numel() for p in module.parameters() if p.requires_grad)\n        table.add_row([name, type(module).__name__, f\"{trainable_params:,}\", f\"{total_params:,}\"])\n\n    total_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    total_params = sum(p.numel() for p in model.parameters())\n    \n    print(table)\n    print(f\"Total trainable parameters: {total_trainable:,} ({total_trainable / 1e6:.2f} M)\")\n    print(f\"Total parameters: {total_params:,} ({total_params / 1e6:.2f} M)\")\n\n\n# def main(data_root_dir, n_samples,  batch_size, patch_size, num_workers):\ndef main(data_cfg, training_cfg):\n    print(\"Data root directory:\", data_cfg.data_root_dir)\n    print(\"========================\")\n    print(\"Dataset config:\", data_cfg)\n    print(\"========================\")\n    print(\"Training config:\", training_cfg)\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    os.makedirs(training_cfg.experiment_out_dir, exist_ok=True)\n    logger = CSVLogger(\"logs\", name=f\"{training_cfg.experiment_out_dir}/metrics_{timestamp}\")\n\n    aug = K.AugmentationSequential(\n        K.RandomResizedCrop(size=(training_cfg.target_size, training_cfg.target_size), scale=(0.4, 1.0)),\n        K.RandomHorizontalFlip(),\n        K.RandomVerticalFlip(),\n        K.RandomGaussianBlur(kernel_size=(7,7), sigma=(0.1, 1.5), p=0.3),\n        K.RandomBrightness(brightness=(0.85, 1.15), p=0.5),\n        data_keys=['input'],\n    )\n\n    if not os.path.exists(data_cfg.data_root_dir):\n        raise FileNotFoundError(f\"Data root directory does not exist: {data_cfg.data_root_dir}\")\n    scenes = sorted(glob.glob(os.path.join(data_cfg.data_root_dir, \"*/\")))\n    bands = [\"B1\",\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B7\",\"B8\",\"B8A\",\"B9\",\"B11\",\"B12\"]\n    # ========================\n    # Compute dataset statistics (mean, std)\n    # ========================\n    if data_cfg.compute_stats:\n        # start_time = time.time()\n        #scenes = sorted(glob.glob(os.path.join(data_cfg.data_root_dir, \"*/\")))\n        # end_time = time.time()\n\n        # print(f\"Found {len(scenes)} scenes in {end_time-start_time:.2f} seconds\")\n\n        # bands = [\"B1\",\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B7\",\"B8\",\"B8A\",\"B9\",\"B11\",\"B12\"]\n        # temp_dataset = SSLDataset(scenes, bands, patch_size=data_cfg.patch_size)\n        \n        temp_dataset = SSLDataset(\n            data_dir = data_cfg.data_root_dir, \n            split_path= data_cfg.split_path,\n            split = data_cfg.stats_split,\n        )\n        import time\n        start_time = time.time()\n        mean, std = calculate_stats_parallel(temp_dataset, batch_size=data_cfg.batch_size, num_workers=data_cfg.num_workers)\n\n        # mean, std = calculate_stats_parallel(temp_dataset, n_samples=data_cfg.n_samples, batch_size=data_cfg.batch_size, num_workers=data_cfg.num_workers)\n        end_time = time.time()\n        print(f\"calculate_stats time: {(end_time-start_time)/60:.2f} min\")\n        print(\"Mean:\", mean)\n        print(\"Std:\", std)\n        mean = mean.tolist()\n        std = std.tolist()\n    else:\n        print(\"Using pre-computed mean and std\")\n        mean =[1352.7405, 1114.1317, 1031.6226,  931.7097, 1177.4148, 1964.9401,\n        2328.8032, 2256.2468,  719.3728,   13.1277, 1781.8745, 1099.7833,\n        2546.1345]\n        \n        std= [ 240.9302,  328.5911,  392.6075,  587.9294,  569.9808,  883.7220,\n        1114.2388, 1143.4304,  400.1378,    8.8553, 1020.8838,  760.5560,\n        1267.6642]\n\n\n    # ========================\n    # Train MoCo model\n    # ========================\n    transform = transforms.Compose([\n        transforms.Resize((training_cfg.target_size, training_cfg.target_size)),\n        transforms.Normalize(mean=mean, std=std)\n    ])\n    dataset= SSLDataset(data_cfg.data_root_dir, data_cfg.split_path, data_cfg.split, transforms=transform)\n    # dataset = SSLDataset(scenes, bands, transforms=transform, patch_size=training_cfg.target_size)\n    print(len(dataset))\n    print(dataset[0]['image'].shape)\n\n    data_loader = DataLoader(\n        dataset,\n        batch_size=training_cfg.batch_size,\n        shuffle=False,\n        num_workers=data_cfg.num_workers,\n        worker_init_fn=seed_worker,\n        generator=g\n    )\n    num_batches = len(data_loader)\n    print(\"Number of batches:\", num_batches)\n\n    task = MoCoTask(\n        model=training_cfg.model,      \n        weights= ResNet18_Weights.SENTINEL2_ALL_MOCO,\n        in_channels=training_cfg.in_channels,       \n        version=training_cfg.version,             # MoCo v2\n        size=training_cfg.target_size,          \n        augmentation1=aug,\n        augmentation2=aug,\n        lr=training_cfg.lr,\n        memory_bank_size=training_cfg.memory_bank_size,\n        temperature=training_cfg.temperature,\n    )\n\n    # -----------------------------\n    # PEFT / Full Fine-Tuning Logic\n    # -----------------------------\n    if training_cfg.use_peft:\n        print(\"Using PEFT: freezing backbone except last block, training projection head...\")\n        for name, param in task.backbone.named_parameters():\n            if \"layer4\" in name:      # optionally fine-tune last residual block\n                param.requires_grad = True\n            else:\n                param.requires_grad = False\n    else:\n        print(\"Full fine-tuning: backbone and projection head trainable...\")\n        for param in task.backbone.parameters():\n            param.requires_grad = True\n\n    # Momentum backbone always frozen\n    for param in task.backbone_momentum.parameters():\n        param.requires_grad = False\n\n    # Projection head always trainable\n    for param in task.projection_head.parameters():\n        param.requires_grad = True\n\n    # Example usage for your task\n    summary_trainable(task)\n\n    checkpoint_callback = ModelCheckpoint(\n      dirpath=training_cfg.experiment_out_dir,\n      filename=\"ssl-best-{epoch:02d}\",\n      monitor=\"train_loss\",\n      mode=\"min\",\n      save_top_k=1\n    )\n\n\n    trainer = Trainer(\n        max_epochs=training_cfg.max_epochs,\n        enable_progress_bar=True, \n        log_every_n_steps=num_batches,\n        precision=16,\n        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n        devices=[0] if torch.cuda.is_available() else 1,\n    \tdeterministic=True,\n        callbacks=[checkpoint_callback],\n        logger=logger)\n    import time\n    start_time=time.time()\n    trainer.fit(task, data_loader)\n    end_time=time.time()\n    print(f\"Training time: {(end_time-start_time)/60} min\")\n\n    torch.save(task.backbone.state_dict(),f\"{training_cfg.experiment_out_dir}/ssl_backbone_{timestamp}.pth\")\n    torch.save(task.projection_head.state_dict(), f\"{training_cfg.experiment_out_dir}/projection_head_{timestamp}.pth\")\n    trainer.save_checkpoint(f\"{training_cfg.experiment_out_dir}/ssl_ckpt_{timestamp}.ckpt\")\n\n\nif __name__ == \"__main__\":\n    device =  \"cpu\"\n    target_num_workers = int(os.cpu_count()*0.75)  # Use 75% of available CPU cores\n    print(\"Using device:\", device)\n    print(\"CPU cores available:\", os.cpu_count())\n    print(\"CPU cores using:\", target_num_workers)\n\n    parser = argparse.ArgumentParser(description=\"Calculate dataset statistics\")\n    parser.add_argument(\n        \"--data_root_dir\",\n        type=str,\n        default=\"/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSATallBands\",\n        help=\"Path to the root directory of scenes\"\n    )\n    \n    parser.add_argument(\n        \"--split_path\",\n        type=str,\n        default=\"/kaggle/working/eurosat_all_bands_split.csv\",\n        help=\"Path to the split file\"\n    )\n\n    parser.add_argument(\n        \"--n_samples\",\n        type=int,\n        default=500, # Set to None to use the entire dataset\n        help=\"Number of samples to calculate statistics on\"\n    )\n\n    parser.add_argument(\n        \"--num_workers\",\n        type=int,\n        default=target_num_workers,\n        help=\"Number of workers for data loading\"\n    )\n    \n    # args = parser.parse_args()\n    args, unknown = parser.parse_known_args()\n\n    # Training configuration\n    \n    \n    data_cfg = DataConfig(\n        data_root_dir=args.data_root_dir,\n        split_path=args.split_path,\n        stats_split=\"subset1\", # options: full_ssl, subset1, subset2, subset3, subset4\n        split =\"subset1\",\n        compute_stats=False,\n        # n_samples=args.n_samples, # only used for stats calculation, not training\n        num_workers=args.num_workers,\n        batch_size=8, # only used for stats calculation, not training\n        patch_size=64, # only used for stats calculation, not training\n    )\n\n    training_cfg = TrainingConfig(\n        experiment_out_dir=f\"/kaggle/working/output/ssl_v1_e20_b96_mem_16k\",\n        model=\"resnet18\",\n        # weights= ResNet50_Weights.SENTINEL2_ALL_MOCO,\n        in_channels=13,\n        version=2,\n        lr=1e-4,\n        use_peft=False,\n        temperature=0.15,\n        memory_bank_size=100, #4096, #2048\n        target_size=64,\n        batch_size=16,\n        max_epochs=2,\n    )\n    main(data_cfg, training_cfg)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T13:25:46.229631Z","iopub.execute_input":"2026-02-15T13:25:46.230613Z","iopub.status.idle":"2026-02-15T15:43:40.535525Z","shell.execute_reply.started":"2026-02-15T13:25:46.230573Z","shell.execute_reply":"2026-02-15T15:43:40.533159Z"}},"outputs":[{"name":"stderr","text":"Seed set to 42\n/usr/local/lib/python3.12/dist-packages/torchgeo/trainers/moco.py:209: UserWarning: MoCo v2 only uses 2 layers in its projection head\n  warnings.warn('MoCo v2 only uses 2 layers in its projection head')\n","output_type":"stream"},{"name":"stdout","text":"Using device: cpu\nCPU cores available: 4\nCPU cores using: 3\nData root directory: /kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSATallBands\n========================\nDataset config: DataConfig(data_root_dir='/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSATallBands', split_path='/kaggle/working/eurosat_all_bands_split.csv', stats_split='subset1', split='subset1', compute_stats=False, batch_size=8, patch_size=64, num_workers=3)\n========================\nTraining config: TrainingConfig(experiment_out_dir='/kaggle/working/output/ssl_v1_e20_b96_mem_16k', model='resnet18', in_channels=13, version=2, lr=0.0001, use_peft=False, temperature=0.15, memory_bank_size=100, target_size=64, max_epochs=2, batch_size=16)\nUsing pre-computed mean and std\n5520\ntorch.Size([13, 64, 64])\nNumber of batches: 345\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/lightning/fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py:479: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\nUsing bfloat16 Automatic Mixed Precision (AMP)\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nğŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n","output_type":"stream"},{"name":"stdout","text":"Full fine-tuning: backbone and projection head trainable...\n+--------------------------+------------------------+------------------+--------------+\n|          Module          |          Type          | Trainable Params | Total Params |\n+--------------------------+------------------------+------------------+--------------+\n|         backbone         |         ResNet         |    11,207,872    |  11,207,872  |\n|    backbone_momentum     |         ResNet         |        0         |  11,207,872  |\n|     projection_head      |   MoCoProjectionHead   |    19,931,392    |  19,931,392  |\n| projection_head_momentum |   MoCoProjectionHead   |        0         |  19,931,392  |\n|        criterion         |       NTXentLoss       |        0         |      0       |\n|      augmentation1       | AugmentationSequential |        0         |      0       |\n+--------------------------+------------------------+------------------+--------------+\nTotal trainable parameters: 31,139,264 (31.14 M)\nTotal parameters: 62,278,528 (62.28 M)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n/usr/local/lib/python3.12/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:881: Checkpoint directory /kaggle/working/output/ssl_v1_e20_b96_mem_16k exists and is not empty.\n/usr/local/lib/python3.12/dist-packages/lightning/pytorch/utilities/model_summary/model_summary.py:242: Precision bf16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mName                    \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mType                  \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\nâ”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\nâ”‚\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0mâ”‚ backbone                 â”‚ ResNet                 â”‚ 11.2 M â”‚ train â”‚     0 â”‚\nâ”‚\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0mâ”‚ backbone_momentum        â”‚ ResNet                 â”‚ 11.2 M â”‚ train â”‚     0 â”‚\nâ”‚\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0mâ”‚ projection_head          â”‚ MoCoProjectionHead     â”‚ 19.9 M â”‚ train â”‚     0 â”‚\nâ”‚\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0mâ”‚ projection_head_momentum â”‚ MoCoProjectionHead     â”‚ 19.9 M â”‚ train â”‚     0 â”‚\nâ”‚\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0mâ”‚ criterion                â”‚ NTXentLoss             â”‚      0 â”‚ train â”‚     0 â”‚\nâ”‚\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0mâ”‚ augmentation1            â”‚ AugmentationSequential â”‚      0 â”‚ train â”‚     0 â”‚\nâ””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name                     </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                   </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>â”ƒ\nâ”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>â”‚ backbone                 â”‚ ResNet                 â”‚ 11.2 M â”‚ train â”‚     0 â”‚\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>â”‚ backbone_momentum        â”‚ ResNet                 â”‚ 11.2 M â”‚ train â”‚     0 â”‚\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>â”‚ projection_head          â”‚ MoCoProjectionHead     â”‚ 19.9 M â”‚ train â”‚     0 â”‚\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>â”‚ projection_head_momentum â”‚ MoCoProjectionHead     â”‚ 19.9 M â”‚ train â”‚     0 â”‚\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>â”‚ criterion                â”‚ NTXentLoss             â”‚      0 â”‚ train â”‚     0 â”‚\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>â”‚ augmentation1            â”‚ AugmentationSequential â”‚      0 â”‚ train â”‚     0 â”‚\nâ””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mTrainable params\u001b[0m: 31.1 M                                                                                           \n\u001b[1mNon-trainable params\u001b[0m: 31.1 M                                                                                       \n\u001b[1mTotal params\u001b[0m: 62.3 M                                                                                               \n\u001b[1mTotal estimated model params size (MB)\u001b[0m: 249                                                                        \n\u001b[1mModules in train mode\u001b[0m: 214                                                                                         \n\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 31.1 M                                                                                           \n<span style=\"font-weight: bold\">Non-trainable params</span>: 31.1 M                                                                                       \n<span style=\"font-weight: bold\">Total params</span>: 62.3 M                                                                                               \n<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 249                                                                        \n<span style=\"font-weight: bold\">Modules in train mode</span>: 214                                                                                         \n<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3643fa15ce347289686bfc1bc778abb"}},"metadata":{}},{"name":"stderr","text":"`Trainer.fit` stopped: `max_epochs=2` reached.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"name":"stderr","text":"`weights_only` was not set, defaulting to `False`.\n","output_type":"stream"},{"name":"stdout","text":"Training time: 137.85049577951432 min\n","output_type":"stream"}],"execution_count":22}]}