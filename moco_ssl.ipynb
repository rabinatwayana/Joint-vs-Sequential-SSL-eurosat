{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":1663377,"datasetId":918039,"databundleVersionId":1699701}],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"e0cb307d","cell_type":"markdown","source":"## Self Supervised Learning (SSL)","metadata":{}},{"id":"3266bf3c","cell_type":"code","source":"!pip install torchgeo --quiet\n!pip install lightning --quiet\n!pip install prettytable","metadata":{"execution":{"iopub.status.busy":"2026-02-21T19:47:29.769613Z","iopub.execute_input":"2026-02-21T19:47:29.770194Z","iopub.status.idle":"2026-02-21T19:47:44.473119Z","shell.execute_reply.started":"2026-02-21T19:47:29.770162Z","shell.execute_reply":"2026-02-21T19:47:44.472334Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m688.1/688.1 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m246.1/246.1 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m859.3/859.3 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m853.6/853.6 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m165.6/165.6 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m760.5/760.5 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: prettytable in /usr/local/lib/python3.12/dist-packages (3.17.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prettytable) (0.6.0)\n","output_type":"stream"}],"execution_count":8},{"id":"33810484-8aae-4ffa-870c-9e59c2596d4b","cell_type":"code","source":"import rasterio\n\n# Path to your image\nimg_path = \"/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSATallBands/AnnualCrop/AnnualCrop_1.tif\"\n\n# Open the TIFF\nwith rasterio.open(img_path) as src:\n    print(f\"Number of bands: {src.count}\")\n    print(f\"Width: {src.width}, Height: {src.height}\")\n    \n    # Iterate over bands\n    for i in range(1, src.count + 1):  # rasterio bands are 1-indexed\n        band = src.read(i)\n        print(f\"Band {i} shape: {band.shape}, dtype: {band.dtype}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:29:17.114812Z","iopub.execute_input":"2026-02-21T11:29:17.115065Z","iopub.status.idle":"2026-02-21T11:29:19.163863Z","shell.execute_reply.started":"2026-02-21T11:29:17.115040Z","shell.execute_reply":"2026-02-21T11:29:19.163247Z"}},"outputs":[{"name":"stdout","text":"Number of bands: 13\nWidth: 64, Height: 64\nBand 1 shape: (64, 64), dtype: uint16\nBand 2 shape: (64, 64), dtype: uint16\nBand 3 shape: (64, 64), dtype: uint16\nBand 4 shape: (64, 64), dtype: uint16\nBand 5 shape: (64, 64), dtype: uint16\nBand 6 shape: (64, 64), dtype: uint16\nBand 7 shape: (64, 64), dtype: uint16\nBand 8 shape: (64, 64), dtype: uint16\nBand 9 shape: (64, 64), dtype: uint16\nBand 10 shape: (64, 64), dtype: uint16\nBand 11 shape: (64, 64), dtype: uint16\nBand 12 shape: (64, 64), dtype: uint16\nBand 13 shape: (64, 64), dtype: uint16\n","output_type":"stream"}],"execution_count":2},{"id":"139f2e34-4819-425d-841c-2915e35ef7ac","cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\n\n# ========================\n# Imports\n# ========================\nimport os\nimport random\nfrom datetime import datetime\nimport glob\nimport argparse\n\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, Subset\nimport rasterio\nfrom rasterio.enums import Resampling\nfrom prettytable import PrettyTable\nfrom lightning.pytorch.loggers import CSVLogger\nfrom torchvision import transforms\nfrom lightning.pytorch import Trainer\nimport kornia.augmentation as K\nfrom dataclasses import dataclass\nfrom torchgeo.trainers.moco import MoCoTask\nfrom torchgeo.models.resnet import ResNet18_Weights\nimport pytorch_lightning as pl\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nimport pandas as pd\nfrom lightning.pytorch.callbacks import ModelCheckpoint\nimport time\n\n# ========================\n# Reproducibility\n# ========================\nseed = 42\nos.environ[\"PYTHONHASHSEED\"] = str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\nimport pytorch_lightning as pl\npl.seed_everything(seed, workers=True)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.use_deterministic_algorithms(True)\n\n# Timestamp for logging / checkpoints\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\ndef seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n\ng = torch.Generator()\ng.manual_seed(seed)\n\nCLASS_NAMES = [\n    \"AnnualCrop\",\n    \"Forest\",\n    \"HerbaceousVegetation\",\n    \"Highway\",\n    \"Industrial\",\n    \"Pasture\",\n    \"PermanentCrop\",\n    \"Residential\",\n    \"River\",\n    \"SeaLake\"\n]\n\nCLASS_TO_IDX = {name: idx for idx, name in enumerate(CLASS_NAMES)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T19:49:27.058492Z","iopub.execute_input":"2026-02-21T19:49:27.059190Z","iopub.status.idle":"2026-02-21T19:49:34.607051Z","shell.execute_reply.started":"2026-02-21T19:49:27.059158Z","shell.execute_reply":"2026-02-21T19:49:34.606505Z"}},"outputs":[{"name":"stderr","text":"Seed set to 42\n","output_type":"stream"}],"execution_count":11},{"id":"d307a8e4-6d5d-4d81-979b-c982f2bcc30a","cell_type":"code","source":"@dataclass\nclass DataConfig:\n    data_root_dir: str = \"/home/krschap/rabina/data/s2a\"\n    split_path: str = \"eurosat_all_bands_split.csv\"\n    stats_split: str = \"full_ssl\"  # options: full_ssl, subset1, subset2, subset3, subset4\n    split: str = \"subset1\"\n    compute_stats: bool = True\n    # n_samples: int = None\n    batch_size: int = 64\n    patch_size: int = 264\n    num_workers: int = 1\n\n@dataclass\nclass TrainingConfig:\n    experiment_out_dir: str = f\"ssl_moco_{timestamp}\"\n    model: str = \"resnet18\"\n    in_channels: int = 13\n    version: int = 2\n    lr: float = 1e-4\n    use_peft: bool = False\n    temperature: float = 0.15\n    memory_bank_size: int = 2048\n    target_size: int = 224\n    max_epochs: int = 100\n    batch_size: int =32\n    #devices = []\n\ndef split_dataset(root_dir,csv_output):\n    # --- COLLECT IMAGE INFO ---\n    data=[]\n    # Iterate over each class folder\n    for class_name in os.listdir(root_dir):\n        class_path = os.path.join(root_dir, class_name)\n        # print(class_path)\n        if not os.path.isdir(class_path):\n            continue  # skip files in root_dir\n    \n        # Iterate over images in the class folder\n        for fname in os.listdir(class_path):\n            # if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n            if fname.lower().endswith((\".tif\", \".tiff\")):\n                # path = os.path.join(class_path, fname)\n                rel_path = os.path.join(class_name, fname)\n                data.append({\n                    \"id\": os.path.splitext(fname)[0].split(\"_\")[-1],\n                     \"fname\": fname,\n                    \"rel_path\": rel_path,\n                    \"label\": class_name\n                })\n    # --- CREATE DATAFRAME ---\n    df = pd.DataFrame(data)\n    # print(df.columns)\n    # --- STRATIFIED SPLIT: 80% SSL, 20% Downstream ---\n    ssl_df, downstream_df = train_test_split(\n        df,\n        test_size=0.2,\n        stratify=df['label'],\n        random_state=42\n    )\n    \n    ssl_df['task'] = 'ssl'\n    downstream_df['task'] = 'downstream'\n    \n    df = pd.concat([ssl_df, downstream_df]).reset_index(drop=True)\n    \n    ssl_df = df[df['task'] == 'ssl'].copy()\n    \n    skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n    \n    ssl_splits = np.empty(len(ssl_df), dtype=object)\n    split_names = ['subset1', 'subset2', 'subset3', 'subset4']\n    \n    for fold_idx, (_, val_idx) in enumerate(skf.split(ssl_df, ssl_df['label'])):\n        ssl_splits[val_idx] = split_names[fold_idx]\n    \n    df.loc[ssl_df.index, 'split'] = ssl_splits\n    \n    down_df = df[df['task'] == 'downstream'].copy()\n    # Step 1: Train (70%) vs Temp (30%)\n    train_df, temp_df = train_test_split(\n        down_df,\n        test_size=0.30,\n        stratify=down_df['label'],\n        random_state=42\n    )\n    # Step 2: Temp â†’ Val (15%) + Test (15%)\n    val_df, test_df = train_test_split(\n        temp_df,\n        test_size=0.50,  # half of 30% = 15%\n        stratify=temp_df['label'],\n        random_state=42\n    )\n    # Assign splits back\n    df.loc[train_df.index, 'split'] = 'train'\n    df.loc[val_df.index, 'split'] = 'val'\n    df.loc[test_df.index, 'split'] = 'test'\n    \n    # --- FINAL CHECK ---\n    print(df['task'].value_counts())\n    print(df['split'].value_counts())\n    # print(df.head(10))\n    \n    # --- SAVE CSV ---\n    df.to_csv(csv_output, index=False)\n    print(f\"CSV saved to {csv_output}\")\n\nclass EurosatDataset(Dataset):\n    def __init__(self, data_dir, split_path, split, transforms=None):\n        \"\"\"\n        Args:\n            data_dir (str): Eurosat folder paths.\n            split_path (str): CSV file path containing splits metadata\n            split (str): all, full_ssl, subset1, subset2, subset3, subset4, train, test, val\n            transforms (callable, optional): Optional transform to apply to patches.\n        \"\"\"\n        self.data_dir = data_dir\n        self.split_path = split_path\n        self.transforms = transforms\n        \n        # Precompute all paths based on split\n        self.samples = []\n        self.df= None\n        df=pd.read_csv(split_path)\n        \n        if split==\"full_ssl\":\n            self.df=df[df['task'] == \"ssl\"].reset_index(drop=True)\n        else:\n            self.df=df[df['split'] == split].reset_index(drop=True)\n        self.samples = self.df['rel_path'].tolist()\n\n        print(f\"len(df): {len(self.df)}\")\n        print(f\"len(samples): {len(self.samples)}\")\n        \n\n    def __len__(self):\n        return len(self.samples)\n    \n\n    # def __getitem__(self, idx):\n    #     sample_path = os.path.join(self.data_dir, self.samples[idx])\n        \n    #     with Image.open(sample_path) as img:\n    #         patch_tensor = img.convert(\"RGB\")\n    #     if self.transforms:\n    #         patch_tensor = self.transforms(patch_tensor)\n\n    #     return {\"image\": patch_tensor}\n    \n    def __getitem__(self, idx):\n        sample_path = os.path.join(self.data_dir, self.samples[idx])\n    \n        # --- Read TIFF with rasterio ---\n        with rasterio.open(sample_path) as src:\n            # Read all bands as float32\n            bands = [src.read(b).astype(np.float32) for b in range(1, src.count + 1)]\n        \n        # Stack bands to shape [C, H, W]\n        img_array = np.stack(bands, axis=0)\n    \n        # --- Convert to torch tensor ---\n        patch_tensor = torch.tensor(img_array, dtype=torch.float32)\n    \n        # --- Apply transforms if provided ---\n        if self.transforms:\n            patch_tensor = self.transforms(patch_tensor)\n\n        # --- map string label to int ---\n        class_name = self.df.iloc[idx]['label']  # the string label\n        label_idx = CLASS_TO_IDX[class_name]\n    \n        # return patch_tensor, label_idx\n    \n        return {\"image\": patch_tensor, \"label\": label_idx}\n\ndef calculate_stats_parallel(dataset, batch_size=16, num_workers=4):\n\n    n_samples = len(dataset)\n    print(f\"Total samples in dataset: {n_samples}\")\n\n    # if n_samples is not None:\n    #     n = min(total, n_samples)\n    #     print(f\"Calculating stats on {n} randomly selected samples...\")\n    #     # Randomly select a subset of indices for efficiency\n    #     np.random.seed(seed)\n    #     indices = np.random.choice(total, size=n, replace=False)\n    #     subset = Subset(dataset, indices)\n    # else:\n    print(f\"Calculating stats on the entire dataset...\")\n    # subset = dataset\n    # n_samples=total\n\n    loader = DataLoader(\n        dataset,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=num_workers,\n        worker_init_fn=seed_worker,\n        generator=g\n    )\n\n    channel_sum = 0.0\n    channel_sum_sq = 0.0\n    num_pixels = 0\n\n    total_batches = len(loader)\n    print(f\"Total batches to process: {total_batches}\")\n    for batch_idx, batch in enumerate(loader, start=1):\n        imgs = batch[\"image\"]\n        b, c, h, w = imgs.shape\n        channel_sum += imgs.sum(dim=(0, 2, 3))\n        channel_sum_sq += (imgs**2).sum(dim=(0, 2, 3))\n        num_pixels += b * h * w\n\n        if batch_idx % 100 == 0 or batch_idx == total_batches:\n            print(f\"Processed batch {batch_idx}/{total_batches} \")\n                # f\"â‰ˆ {batch_idx * b}/{n_samples} samples\")\n\n    mean = channel_sum / num_pixels\n    torch.set_printoptions(sci_mode=False, precision=4)\n    # std  = torch.sqrt(channel_sum_sq / num_pixels - mean**2)\n    variance = channel_sum_sq / num_pixels - mean**2\n    variance = torch.clamp(variance, min=0)  # Avoid negative values\n    # Add small epsilon to avoid sqrt(0) issues\n    std = torch.sqrt(variance + 1e-8)\n    return mean, std\n\ndef summary_trainable(model):\n    table = PrettyTable()\n    table.field_names = [\"Module\", \"Type\", \"Trainable Params\", \"Total Params\"]\n\n    for name, module in model.named_children():\n        total_params = sum(p.numel() for p in module.parameters())\n        trainable_params = sum(p.numel() for p in module.parameters() if p.requires_grad)\n        table.add_row([name, type(module).__name__, f\"{trainable_params:,}\", f\"{total_params:,}\"])\n\n    total_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    total_params = sum(p.numel() for p in model.parameters())\n    \n    print(table)\n    print(f\"Total trainable parameters: {total_trainable:,} ({total_trainable / 1e6:.2f} M)\")\n    print(f\"Total parameters: {total_params:,} ({total_params / 1e6:.2f} M)\")\n\n# def main(data_root_dir, n_samples,  batch_size, patch_size, num_workers):\ndef main(data_cfg, training_cfg):\n    print(\"Data root directory:\", data_cfg.data_root_dir)\n    print(\"========================\")\n    print(\"Dataset config:\", data_cfg)\n    print(\"========================\")\n    print(\"Training config:\", training_cfg)\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    os.makedirs(training_cfg.experiment_out_dir, exist_ok=True)\n    logger = CSVLogger(training_cfg.experiment_out_dir, name=f\"metrics_{timestamp}\")\n\n    aug = K.AugmentationSequential(\n        K.RandomResizedCrop(size=(training_cfg.target_size, training_cfg.target_size), scale=(0.4, 1.0)),\n        K.RandomHorizontalFlip(),\n        K.RandomVerticalFlip(),\n        K.RandomGaussianBlur(kernel_size=(7,7), sigma=(0.1, 1.5), p=0.3),\n        K.RandomBrightness(brightness=(0.85, 1.15), p=0.5),\n        data_keys=['input'],\n    )\n\n    if not os.path.exists(data_cfg.data_root_dir):\n        raise FileNotFoundError(f\"Data root directory does not exist: {data_cfg.data_root_dir}\")\n    scenes = sorted(glob.glob(os.path.join(data_cfg.data_root_dir, \"*/\")))\n    bands = [\"B1\",\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B7\",\"B8\",\"B8A\",\"B9\",\"B11\",\"B12\"]\n    # ========================\n    # Compute dataset statistics (mean, std)\n    # ========================\n    if data_cfg.compute_stats:\n        # start_time = time.time()\n        #scenes = sorted(glob.glob(os.path.join(data_cfg.data_root_dir, \"*/\")))\n        # end_time = time.time()\n\n        # print(f\"Found {len(scenes)} scenes in {end_time-start_time:.2f} seconds\")\n\n        # bands = [\"B1\",\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B7\",\"B8\",\"B8A\",\"B9\",\"B11\",\"B12\"]\n        # temp_dataset = SSLDataset(scenes, bands, patch_size=data_cfg.patch_size)\n        \n        temp_dataset = EurosatDataset(\n            data_dir = data_cfg.data_root_dir, \n            split_path= data_cfg.split_path,\n            split = data_cfg.stats_split,\n        )\n        import time\n        start_time = time.time()\n        mean, std = calculate_stats_parallel(temp_dataset, batch_size=data_cfg.batch_size, num_workers=data_cfg.num_workers)\n\n        # mean, std = calculate_stats_parallel(temp_dataset, n_samples=data_cfg.n_samples, batch_size=data_cfg.batch_size, num_workers=data_cfg.num_workers)\n        end_time = time.time()\n        print(f\"calculate_stats time: {(end_time-start_time)/60:.2f} min\")\n        print(\"Mean:\", mean)\n        print(\"Std:\", std)\n        mean = mean.tolist()\n        std = std.tolist()\n    else:\n        print(\"Using pre-computed mean and std\")\n        mean =[1354.4231, 1116.6886, 1035.6735,  938.2608, 1184.0359, 1969.5629,\n        2332.6990, 2260.2139,  723.8848,   13.1612, 1785.6721, 1101.3131,\n        2549.8162]\n        \n        std= [ 243.4430,  331.7848,  396.9748,  596.1298,  577.0484,  887.0798,\n        1116.7583, 1146.2135,  404.7274,    9.5821, 1028.9261,  766.2137,\n        1271.2732]\n\n    # ========================\n    # Train MoCo model\n    # ========================\n    transform = transforms.Compose([\n        transforms.Resize((training_cfg.target_size, training_cfg.target_size)),\n        transforms.Normalize(mean=mean, std=std)\n    ])\n    dataset= EurosatDataset(data_cfg.data_root_dir, data_cfg.split_path, data_cfg.split, transforms=transform)\n    # dataset = SSLDataset(scenes, bands, transforms=transform, patch_size=training_cfg.target_size)\n    print(len(dataset))\n    print(dataset[0]['image'].shape)\n\n    data_loader = DataLoader(\n        dataset,\n        batch_size=training_cfg.batch_size,\n        shuffle=False,\n        num_workers=data_cfg.num_workers,\n        worker_init_fn=seed_worker,\n        generator=g\n    )\n    num_batches = len(data_loader)\n    print(\"Number of batches:\", num_batches)\n\n    task = MoCoTask(\n        model=training_cfg.model,      \n        weights= None,\n        # weights= ResNet18_Weights.SENTINEL2_ALL_MOCO,\n        in_channels=training_cfg.in_channels,       \n        version=training_cfg.version,             # MoCo v2\n        size=training_cfg.target_size,          \n        augmentation1=aug,\n        augmentation2=aug,\n        lr=training_cfg.lr,\n        memory_bank_size=training_cfg.memory_bank_size,\n        temperature=training_cfg.temperature,\n    )\n\n    # -----------------------------\n    # PEFT / Full Fine-Tuning Logic\n    # -----------------------------\n    if training_cfg.use_peft:\n        print(\"Using PEFT: freezing backbone except last block, training projection head...\")\n        for name, param in task.backbone.named_parameters():\n            if \"layer4\" in name:      # optionally fine-tune last residual block\n                param.requires_grad = True\n            else:\n                param.requires_grad = False\n    else:\n        print(\"Full fine-tuning: backbone and projection head trainable...\")\n        for param in task.backbone.parameters():\n            param.requires_grad = True\n\n    # Momentum backbone always frozen\n    for param in task.backbone_momentum.parameters():\n        param.requires_grad = False\n\n    # Projection head always trainable\n    for param in task.projection_head.parameters():\n        param.requires_grad = True\n\n    # Example usage for your task\n    summary_trainable(task)\n\n    checkpoint_callback = ModelCheckpoint(\n      dirpath=training_cfg.experiment_out_dir,\n      # filename=\"ssl-best-{epoch:02d}\",\n      monitor=\"train_loss\",\n      mode=\"min\",\n      save_top_k=1,\n      save_last=True\n    )\n\n\n    trainer = Trainer(\n        max_epochs=training_cfg.max_epochs,\n        enable_progress_bar=True, \n        log_every_n_steps=num_batches,\n        precision=16,\n        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n        devices=[0] if torch.cuda.is_available() else 1,\n    \tdeterministic=True,\n        callbacks=[checkpoint_callback],\n        logger=logger)\n    import time\n    start_time=time.time()\n    trainer.fit(task, data_loader)\n    end_time=time.time()\n    print(f\"Training time: {(end_time-start_time)/60} min\")\n\n    # torch.save(task.backbone.state_dict(),f\"{training_cfg.experiment_out_dir}/ssl_backbone_{timestamp}.pth\")\n    # torch.save(task.projection_head.state_dict(), f\"{training_cfg.experiment_out_dir}/projection_head_{timestamp}.pth\")\n    # trainer.save_checkpoint(f\"{training_cfg.experiment_out_dir}/ssl_ckpt_{timestamp}.ckpt\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T19:49:47.343278Z","iopub.execute_input":"2026-02-21T19:49:47.343999Z","iopub.status.idle":"2026-02-21T19:49:47.376783Z","shell.execute_reply.started":"2026-02-21T19:49:47.343967Z","shell.execute_reply":"2026-02-21T19:49:47.375999Z"}},"outputs":[],"execution_count":13},{"id":"630c0f4c-f9ca-4059-bf6b-4e55081cd17e","cell_type":"code","source":"split_dataset(root_dir=\"/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSATallBands\",\n              csv_output=\"/kaggle/working/eurosat_all_bands_split.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:09:21.028273Z","iopub.execute_input":"2026-02-21T11:09:21.028608Z","iopub.status.idle":"2026-02-21T11:09:21.793558Z","shell.execute_reply.started":"2026-02-21T11:09:21.028563Z","shell.execute_reply":"2026-02-21T11:09:21.792890Z"}},"outputs":[{"name":"stdout","text":"task\nssl           22077\ndownstream     5520\nName: count, dtype: int64\nsplit\nsubset1    5520\nsubset4    5519\nsubset2    5519\nsubset3    5519\ntrain      3864\ntest        828\nval         828\nName: count, dtype: int64\nCSV saved to /kaggle/working/eurosat_all_bands_split.csv\n","output_type":"stream"}],"execution_count":5},{"id":"d402297f-2f9f-42ec-97b7-724625cc92c4","cell_type":"code","source":"if __name__ == \"__main__\":\n    # device =  \"gpu\"\n    target_num_workers = int(os.cpu_count()*0.75)  # Use 75% of available CPU cores\n    # print(\"Using device:\", device)\n    print(\"CPU cores available:\", os.cpu_count())\n    print(\"CPU cores using:\", target_num_workers)\n\n    parser = argparse.ArgumentParser(description=\"Calculate dataset statistics\")\n    parser.add_argument(\n        \"--data_root_dir\",\n        type=str,\n        default=\"/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSATallBands\",\n        help=\"Path to the root directory of scenes\"\n    )\n    \n    parser.add_argument(\n        \"--split_path\",\n        type=str,\n        default=\"/kaggle/working/eurosat_all_bands_split.csv\",\n        help=\"Path to the split file\"\n    )\n\n    # parser.add_argument(\n    #     \"--n_samples\",\n    #     type=int,\n    #     default=500, # Set to None to use the entire dataset\n    #     help=\"Number of samples to calculate statistics on\"\n    # )\n\n    parser.add_argument(\n        \"--num_workers\",\n        type=int,\n        default=target_num_workers,\n        help=\"Number of workers for data loading\"\n    )\n    \n    # args = parser.parse_args()\n    args, unknown = parser.parse_known_args()\n\n    # Training configuration\n    \n    \n    data_cfg = DataConfig(\n        data_root_dir=args.data_root_dir,\n        split_path=args.split_path,\n        stats_split=\"full_ssl\", # options: full_ssl, subset1, subset2, subset3, subset4\n        split =\"full_ssl\",\n        compute_stats=True,\n        # n_samples=args.n_samples, # only used for stats calculation, not training\n        num_workers=args.num_workers,\n        batch_size=64, # only used for stats calculation, not training\n        patch_size=64, # only used for stats calculation, not training\n    )\n\n    training_cfg = TrainingConfig(\n        experiment_out_dir=f\"/kaggle/working/output/full_ssl_v1\",\n        model=\"resnet18\",\n        # weights= ResNet50_Weights.SENTINEL2_ALL_MOCO,\n        in_channels=13,\n        version=2,\n        lr=0.015, #lr = 0.03 Ã— (batch_size / 256)\n        # weight_decay=1e-4,\n        # optimizer=\"sgd\",\n        # scheduler=\"cosine\",\n        use_peft=False,\n        temperature=0.15,\n        memory_bank_size=4096, #4096, #2048\n        target_size=64,\n        batch_size=128,\n        max_epochs=100,\n    )\n    main(data_cfg, training_cfg)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:30:58.848300Z","iopub.execute_input":"2026-02-21T11:30:58.848853Z","iopub.status.idle":"2026-02-21T13:53:20.173458Z","shell.execute_reply.started":"2026-02-21T11:30:58.848817Z","shell.execute_reply":"2026-02-21T13:53:20.172794Z"}},"outputs":[{"name":"stdout","text":"CPU cores available: 4\nCPU cores using: 3\nData root directory: /kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSATallBands\n========================\nDataset config: DataConfig(data_root_dir='/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSATallBands', split_path='/kaggle/working/eurosat_all_bands_split.csv', stats_split='full_ssl', split='full_ssl', compute_stats=True, batch_size=64, patch_size=64, num_workers=3)\n========================\nTraining config: TrainingConfig(experiment_out_dir='/kaggle/working/output/full_ssl_v1', model='resnet18', in_channels=13, version=2, lr=0.015, use_peft=False, temperature=0.15, memory_bank_size=4096, target_size=64, max_epochs=100, batch_size=128)\nlen(df): 22077\nlen(samples): 22077\nTotal samples in dataset: 22077\nCalculating stats on the entire dataset...\nTotal batches to process: 345\nProcessed batch 100/345 \nProcessed batch 200/345 \nProcessed batch 300/345 \nProcessed batch 345/345 \ncalculate_stats time: 3.84 min\nMean: tensor([1354.4231, 1116.6886, 1035.6735,  938.2608, 1184.0359, 1969.5629,\n        2332.6990, 2260.2139,  723.8848,   13.1612, 1785.6721, 1101.3131,\n        2549.8162])\nStd: tensor([ 243.4430,  331.7848,  396.9748,  596.1298,  577.0484,  887.0798,\n        1116.7583, 1146.2135,  404.7274,    9.5821, 1028.9261,  766.2137,\n        1271.2732])\nlen(df): 22077\nlen(samples): 22077\n22077\ntorch.Size([13, 64, 64])\nNumber of batches: 173\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchgeo/trainers/moco.py:209: UserWarning: MoCo v2 only uses 2 layers in its projection head\n  warnings.warn('MoCo v2 only uses 2 layers in its projection head')\n/usr/local/lib/python3.12/dist-packages/lightning/fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\nUsing 16bit Automatic Mixed Precision (AMP)\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nğŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n","output_type":"stream"},{"name":"stdout","text":"Full fine-tuning: backbone and projection head trainable...\n+--------------------------+------------------------+------------------+--------------+\n|          Module          |          Type          | Trainable Params | Total Params |\n+--------------------------+------------------------+------------------+--------------+\n|         backbone         |         ResNet         |    11,207,872    |  11,207,872  |\n|    backbone_momentum     |         ResNet         |        0         |  11,207,872  |\n|     projection_head      |   MoCoProjectionHead   |    19,931,392    |  19,931,392  |\n| projection_head_momentum |   MoCoProjectionHead   |        0         |  19,931,392  |\n|        criterion         |       NTXentLoss       |        0         |      0       |\n|      augmentation1       | AugmentationSequential |        0         |      0       |\n+--------------------------+------------------------+------------------+--------------+\nTotal trainable parameters: 31,139,264 (31.14 M)\nTotal parameters: 62,278,528 (62.28 M)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n/usr/local/lib/python3.12/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:881: Checkpoint directory /kaggle/working/output/full_ssl_v1 exists and is not empty.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n/usr/local/lib/python3.12/dist-packages/lightning/pytorch/utilities/model_summary/model_summary.py:242: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mName                    \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mType                  \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\nâ”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\nâ”‚\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0mâ”‚ backbone                 â”‚ ResNet                 â”‚ 11.2 M â”‚ train â”‚     0 â”‚\nâ”‚\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0mâ”‚ backbone_momentum        â”‚ ResNet                 â”‚ 11.2 M â”‚ train â”‚     0 â”‚\nâ”‚\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0mâ”‚ projection_head          â”‚ MoCoProjectionHead     â”‚ 19.9 M â”‚ train â”‚     0 â”‚\nâ”‚\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0mâ”‚ projection_head_momentum â”‚ MoCoProjectionHead     â”‚ 19.9 M â”‚ train â”‚     0 â”‚\nâ”‚\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0mâ”‚ criterion                â”‚ NTXentLoss             â”‚      0 â”‚ train â”‚     0 â”‚\nâ”‚\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0mâ”‚ augmentation1            â”‚ AugmentationSequential â”‚      0 â”‚ train â”‚     0 â”‚\nâ””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name                     </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                   </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>â”ƒ\nâ”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>â”‚ backbone                 â”‚ ResNet                 â”‚ 11.2 M â”‚ train â”‚     0 â”‚\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>â”‚ backbone_momentum        â”‚ ResNet                 â”‚ 11.2 M â”‚ train â”‚     0 â”‚\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>â”‚ projection_head          â”‚ MoCoProjectionHead     â”‚ 19.9 M â”‚ train â”‚     0 â”‚\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>â”‚ projection_head_momentum â”‚ MoCoProjectionHead     â”‚ 19.9 M â”‚ train â”‚     0 â”‚\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>â”‚ criterion                â”‚ NTXentLoss             â”‚      0 â”‚ train â”‚     0 â”‚\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>â”‚ augmentation1            â”‚ AugmentationSequential â”‚      0 â”‚ train â”‚     0 â”‚\nâ””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mTrainable params\u001b[0m: 31.1 M                                                                                           \n\u001b[1mNon-trainable params\u001b[0m: 31.1 M                                                                                       \n\u001b[1mTotal params\u001b[0m: 62.3 M                                                                                               \n\u001b[1mTotal estimated model params size (MB)\u001b[0m: 249                                                                        \n\u001b[1mModules in train mode\u001b[0m: 214                                                                                         \n\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 31.1 M                                                                                           \n<span style=\"font-weight: bold\">Non-trainable params</span>: 31.1 M                                                                                       \n<span style=\"font-weight: bold\">Total params</span>: 62.3 M                                                                                               \n<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 249                                                                        \n<span style=\"font-weight: bold\">Modules in train mode</span>: 214                                                                                         \n<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cbf4c9da811440481f4d0d01bd94093"}},"metadata":{}},{"name":"stderr","text":"IOPub message rate exceeded.\nThe Jupyter server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--ServerApp.iopub_msg_rate_limit`.\n\nCurrent values:\nServerApp.iopub_msg_rate_limit=10000.0 (msgs/sec)\nServerApp.rate_limit_window=1.0 (secs)\n\n`Trainer.fit` stopped: `max_epochs=100` reached.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"name":"stdout","text":"Training time: 138.5041580716769 min\n","output_type":"stream"}],"execution_count":6},{"id":"7cd91566-dfb3-43fc-be51-236431c2e7ce","cell_type":"code","source":"import shutil\n\nshutil.make_archive(\n    \"/kaggle/working/output/full_ssl_v1\", \n    'zip', \n    \"/kaggle/working/output/full_ssl_v1\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T19:08:48.802849Z","iopub.execute_input":"2026-02-21T19:08:48.803158Z","iopub.status.idle":"2026-02-21T19:09:25.084715Z","shell.execute_reply.started":"2026-02-21T19:08:48.803133Z","shell.execute_reply":"2026-02-21T19:09:25.084072Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/output/full_ssl_v1.zip'"},"metadata":{}}],"execution_count":1},{"id":"4f4dacc9-5a6d-4207-8256-b144e85d14ed","cell_type":"markdown","source":"Model Training","metadata":{}},{"id":"4141f75c-b1f0-4b0d-878a-114aa72a4d98","cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport pytorch_lightning as pl\n# from lightning.pytorch import Trainer\nfrom lightning.pytorch.callbacks import ModelCheckpoint\n# from torch.utils.data import DataLoader\nimport torchvision.transforms as T\n# from torchvision.datasets import ImageFolder\nfrom torchvision.models import resnet18\nfrom pytorch_lightning.callbacks import EarlyStopping\nfrom torchmetrics.classification import MulticlassF1Score, MulticlassAccuracy\nfrom datetime import datetime\n\nfrom prettytable import PrettyTable\nfrom lightning.pytorch.loggers import CSVLogger\nfrom torchvision import transforms\nfrom lightning.pytorch import Trainer\n\n# ---------- Downstream Lightning Module ----------\nclass EuroSATClassifier(pl.LightningModule):\n    def __init__(self, backbone, num_classes, lr=1e-3):\n        super().__init__()\n        self.backbone = backbone\n        # freeze backbone by default\n        for p in self.backbone.parameters():\n            p.requires_grad = False\n\n        # classification head\n        # flatten features and map to num_classes\n        self.classifier = nn.Linear(self.backbone.out_features, num_classes)\n        self.criterion = nn.CrossEntropyLoss()\n        self.lr = lr\n        #train \n        # Metrics\n        self.train_acc = MulticlassAccuracy(num_classes=num_classes)\n        self.val_acc = MulticlassAccuracy(num_classes=num_classes)\n        \n        self.train_f1_macro = MulticlassF1Score(num_classes=num_classes, average=\"macro\")\n        \n        # Validation metrics\n        self.val_f1_macro = MulticlassF1Score(num_classes=num_classes, average=\"macro\")\n        \n\n    def forward(self, x):\n        feats = self.backbone(x)\n        feats = feats.flatten(1)\n        out = self.classifier(feats)\n        return out\n\n    def training_step(self, batch, batch_idx):\n        # x, y = batch\n        x, y = batch['image'], batch['label']\n        y_hat = self(x)\n        loss = self.criterion(y_hat, y)\n    \n        # update metrics\n        self.train_acc(y_hat, y)\n        self.train_f1_macro(y_hat, y)\n    \n        # log\n        self.log(\"train_loss\", loss, prog_bar=True)\n        self.log(\"train_acc\", self.train_acc, prog_bar=False, on_epoch=True, on_step=False)\n        self.log(\"train_f1_macro\", self.train_f1_macro, prog_bar=True, on_epoch=True, on_step=False)\n\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch['image'], batch['label']\n        y_hat = self(x)\n        loss = self.criterion(y_hat, y)\n    \n        # update metrics\n        self.val_acc(y_hat, y)\n        self.val_f1_macro(y_hat, y)\n    \n        # log\n        self.log(\"val_loss\", loss, prog_bar=True)\n        self.log(\"val_acc\", self.val_acc, prog_bar=False, on_epoch=True, on_step=False)\n        self.log(\"val_f1_macro\", self.val_f1_macro, prog_bar=True, on_epoch=True, on_step=False)\n    \n        return loss\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.classifier.parameters(), lr=self.lr)\n\n\n# --------- Load pretrained backbone from MoCo checkpoint ---------\n\n# def load_moco_backbone(ckpt_path: str):\n#     \"\"\"\n#     Load a MoCo pretrained backbone from SSL checkpoint.\n#     Assumes the checkpoint stores a ResNet style encoder\n#     with feature dimension in `backbone`.\n#     \"\"\"\n\n#     ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n#     state_dict = ckpt[\"state_dict\"] if \"state_dict\" in ckpt else ckpt\n\n#     # assume the backbone key prefix is something like \"backbone.\"\n#     # strip off the moco projection head weights\n#     backbone_keys = {k.replace(\"backbone.\", \"\"):v\n#                      for k, v in state_dict.items()\n#                      if k.startswith(\"backbone\") and \"projection_head\" not in k}\n\n#     # create a ResNet50 backbone without final FC\n#     model = resnet18(weights=None)\n#     layers = list(model.children())[:-1]  # all layers except final fc\n#     backbone = nn.Sequential(*layers)\n\n#     # load state dict into backbone\n#     backbone.load_state_dict(backbone_keys, strict=False)\n\n#     # record output dim (ResNet50 last conv features)\n#     backbone.out_features = model.fc.in_features\n\n#     return backbone\n\nfrom torchvision.models import resnet18\n\ndef load_moco_backbone(ckpt_path: str, in_channels=13):\n    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n    state_dict = ckpt.get(\"state_dict\", ckpt)\n\n    # Strip MoCo projection head\n    backbone_keys = {\n        k.replace(\"backbone.\", \"\"): v\n        for k, v in state_dict.items()\n        if k.startswith(\"backbone\") and \"projection_head\" not in k\n    }\n\n    # Load ResNet18\n    model = resnet18(weights=None)\n    \n    # Replace first conv layer to accept 13 channels\n    model.conv1 = nn.Conv2d(\n        in_channels,\n        model.conv1.out_channels,\n        kernel_size=model.conv1.kernel_size,\n        stride=model.conv1.stride,\n        padding=model.conv1.padding,\n        bias=model.conv1.bias is not None\n    )\n\n    # Keep all layers except the final FC\n    layers = list(model.children())[:-1]\n    backbone = nn.Sequential(*layers)\n    backbone.out_features = model.fc.in_features\n\n    # Load MoCo weights into backbone (ignore missing keys for conv1)\n    backbone.load_state_dict(backbone_keys, strict=False)\n\n    return backbone\n\n\n# --------------- Main Function -----------------\n\ndef main():\n    import argparse\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--data_root_dir\", type=str, default=\"/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSATallBands\",\n                        help=\"Path to EuroSAT downstream data with subfolders per class\")\n    parser.add_argument(\"--split_path\", type=str, default=\"/kaggle/working/eurosat_all_bands_split.csv\",\n                        help=\"Path to split csv\")\n    parser.add_argument(\"--ckpt\", type=str, default=\"/kaggle/working/output/full_ssl_v1/epoch=91-step=15916.ckpt\",\n                        help=\"Path to your MoCo SSL pretrained checkpoint\")\n    parser.add_argument(\"--max_epochs\", type=int, default=100)\n    parser.add_argument(\"--experiment_out_dir\", type=str, default=\"/kaggle/working/full_downstream_v1\")\n    \n    num_workers = int(os.cpu_count()*0.75) \n    lr=1e-3\n    batch_size=32\n    target_size=64\n    \n    args, _ = parser.parse_known_args()\n\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    os.makedirs(args.experiment_out_dir, exist_ok=True)\n\n    \n    logger = CSVLogger(args.experiment_out_dir, name=f\"metrics_{timestamp}\")\n\n\n    # -------- Load Backbone --------\n    backbone = load_moco_backbone(args.ckpt, in_channels=13)\n\n    # -------- Build Classifier LightningModule --------\n    # EuroSAT has 10 classes\n    model = EuroSATClassifier(backbone, num_classes=10, lr=lr)\n\n    print(\"Using pre-computed mean and std\")\n    \n    mean =[1354.4231, 1116.6886, 1035.6735,  938.2608, 1184.0359, 1969.5629,\n        2332.6990, 2260.2139,  723.8848,   13.1612, 1785.6721, 1101.3131,\n        2549.8162]\n        \n    std= [ 243.4430,  331.7848,  396.9748,  596.1298,  577.0484,  887.0798,\n    1116.7583, 1146.2135,  404.7274,    9.5821, 1028.9261,  766.2137,\n    1271.2732]\n\n    # -------- Data Transforms --------\n    transform = transforms.Compose([\n        transforms.Resize((target_size, target_size)),\n        transforms.Normalize(mean=mean, std=std)\n    ])\n    \n    train_ds= EurosatDataset(args.data_root_dir, args.split_path, \"train\", transforms=transform)\n    val_ds= EurosatDataset(args.data_root_dir, args.split_path, \"val\", transforms=transform)\n    \n    train_loader = DataLoader(train_ds, \n                              batch_size=batch_size,\n                              shuffle=True, \n                              num_workers=num_workers, \n                              worker_init_fn=seed_worker,\n                              generator=g)\n    val_loader   = DataLoader(val_ds, \n                              batch_size=batch_size,\n                              shuffle=False, \n                              num_workers=num_workers,\n                              worker_init_fn=seed_worker,\n                              generator=g)\n\n    # -------- Trainer Setup --------\n    checkpoint_cb = ModelCheckpoint(\n        dirpath=args.experiment_out_dir,\n        monitor=\"val_f1_macro\",\n        mode=\"max\", \n        save_top_k=1,\n        save_last=True \n    )\n    early_stop_cb = EarlyStopping(\n        monitor=\"val_f1_macro\",\n        mode=\"max\",\n        patience=20,\n        min_delta=0.005,\n        verbose=True\n    )\n\n    # lr_monitor_cb = LearningRateMonitor(logging_interval=\"epoch\")\n    trainer = pl.Trainer(\n        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n        devices=[0] if torch.cuda.is_available() else 1,\n        max_epochs=args.max_epochs,\n        callbacks=[checkpoint_cb, early_stop_cb],\n        precision=16,\n    \tdeterministic=True,\n        log_every_n_steps=len(train_loader),\n        enable_progress_bar=True,\n        logger=logger\n    )\n\n    # -------- Train --------\n    trainer.fit(model, train_loader, val_loader)\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T19:50:03.600109Z","iopub.execute_input":"2026-02-21T19:50:03.600753Z","iopub.status.idle":"2026-02-21T20:00:57.827738Z","shell.execute_reply.started":"2026-02-21T19:50:03.600725Z","shell.execute_reply":"2026-02-21T20:00:57.827119Z"},"scrolled":true},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/lightning_fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\nUsing 16bit Automatic Mixed Precision (AMP)\n","output_type":"stream"},{"name":"stdout","text":"Using pre-computed mean and std\nlen(df): 3864\nlen(samples): 3864\nlen(df): 828\nlen(samples): 828\n","output_type":"stream"},{"name":"stderr","text":"GPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nğŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n/usr/local/lib/python3.12/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:881: Checkpoint directory /kaggle/working/full_downstream_v1 exists and is not empty.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/model_summary/model_summary.py:242: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mName          \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mType              \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\nâ”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\nâ”‚\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0mâ”‚ backbone       â”‚ Sequential         â”‚ 11.2 M â”‚ train â”‚     0 â”‚\nâ”‚\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0mâ”‚ classifier     â”‚ Linear             â”‚  5.1 K â”‚ train â”‚     0 â”‚\nâ”‚\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0mâ”‚ criterion      â”‚ CrossEntropyLoss   â”‚      0 â”‚ train â”‚     0 â”‚\nâ”‚\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0mâ”‚ train_acc      â”‚ MulticlassAccuracy â”‚      0 â”‚ train â”‚     0 â”‚\nâ”‚\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0mâ”‚ val_acc        â”‚ MulticlassAccuracy â”‚      0 â”‚ train â”‚     0 â”‚\nâ”‚\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0mâ”‚ train_f1_macro â”‚ MulticlassF1Score  â”‚      0 â”‚ train â”‚     0 â”‚\nâ”‚\u001b[2m \u001b[0m\u001b[2m6\u001b[0m\u001b[2m \u001b[0mâ”‚ val_f1_macro   â”‚ MulticlassF1Score  â”‚      0 â”‚ train â”‚     0 â”‚\nâ””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name           </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type               </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>â”ƒ\nâ”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>â”‚ backbone       â”‚ Sequential         â”‚ 11.2 M â”‚ train â”‚     0 â”‚\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>â”‚ classifier     â”‚ Linear             â”‚  5.1 K â”‚ train â”‚     0 â”‚\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>â”‚ criterion      â”‚ CrossEntropyLoss   â”‚      0 â”‚ train â”‚     0 â”‚\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>â”‚ train_acc      â”‚ MulticlassAccuracy â”‚      0 â”‚ train â”‚     0 â”‚\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>â”‚ val_acc        â”‚ MulticlassAccuracy â”‚      0 â”‚ train â”‚     0 â”‚\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>â”‚ train_f1_macro â”‚ MulticlassF1Score  â”‚      0 â”‚ train â”‚     0 â”‚\nâ”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>â”‚ val_f1_macro   â”‚ MulticlassF1Score  â”‚      0 â”‚ train â”‚     0 â”‚\nâ””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mTrainable params\u001b[0m: 5.1 K                                                                                            \n\u001b[1mNon-trainable params\u001b[0m: 11.2 M                                                                                       \n\u001b[1mTotal params\u001b[0m: 11.2 M                                                                                               \n\u001b[1mTotal estimated model params size (MB)\u001b[0m: 44                                                                         \n\u001b[1mModules in train mode\u001b[0m: 73                                                                                          \n\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 5.1 K                                                                                            \n<span style=\"font-weight: bold\">Non-trainable params</span>: 11.2 M                                                                                       \n<span style=\"font-weight: bold\">Total params</span>: 11.2 M                                                                                               \n<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 44                                                                         \n<span style=\"font-weight: bold\">Modules in train mode</span>: 73                                                                                          \n<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72b625883a704c8986a0f53e0765edb6"}},"metadata":{}},{"name":"stderr","text":"Metric val_f1_macro improved. New best score: 0.427\nMetric val_f1_macro improved by 0.067 >= min_delta = 0.005. New best score: 0.494\nMetric val_f1_macro improved by 0.049 >= min_delta = 0.005. New best score: 0.542\nMetric val_f1_macro improved by 0.059 >= min_delta = 0.005. New best score: 0.601\nMetric val_f1_macro improved by 0.013 >= min_delta = 0.005. New best score: 0.614\nMetric val_f1_macro improved by 0.022 >= min_delta = 0.005. New best score: 0.636\nMetric val_f1_macro improved by 0.006 >= min_delta = 0.005. New best score: 0.642\nMetric val_f1_macro improved by 0.008 >= min_delta = 0.005. New best score: 0.650\nMetric val_f1_macro improved by 0.012 >= min_delta = 0.005. New best score: 0.662\nMonitored metric val_f1_macro did not improve in the last 20 records. Best score: 0.662. Signaling Trainer to stop.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}}],"execution_count":14},{"id":"276b1a67-9ece-4ce9-bb10-6bf5e429b696","cell_type":"code","source":"import shutil\n\nshutil.make_archive(\n    \"/kaggle/working/full_downstream_v1\", \n    'zip', \n    \"/kaggle/working/full_downstream_v1\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T20:20:12.572345Z","iopub.execute_input":"2026-02-21T20:20:12.573047Z","iopub.status.idle":"2026-02-21T20:20:19.329562Z","shell.execute_reply.started":"2026-02-21T20:20:12.573006Z","shell.execute_reply":"2026-02-21T20:20:19.328919Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/full_downstream_v1.zip'"},"metadata":{}}],"execution_count":15}]}