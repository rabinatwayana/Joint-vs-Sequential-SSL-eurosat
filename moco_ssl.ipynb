{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1663377,"sourceType":"datasetVersion","datasetId":918039}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"e0cb307d","cell_type":"markdown","source":"## Self Supervised Learning (SSL)","metadata":{}},{"id":"3266bf3c","cell_type":"code","source":"!pip install torchgeo --quiet\n!pip install lightning --quiet\n!pip install prettytable","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T10:15:14.855529Z","iopub.execute_input":"2026-02-14T10:15:14.856356Z","iopub.status.idle":"2026-02-14T10:15:24.273061Z","shell.execute_reply.started":"2026-02-14T10:15:14.856332Z","shell.execute_reply":"2026-02-14T10:15:24.272245Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: prettytable in /usr/local/lib/python3.12/dist-packages (3.16.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prettytable) (0.2.14)\n","output_type":"stream"}],"execution_count":12},{"id":"fce313a0","cell_type":"code","source":"import os\nSEED = 42\n# Environment variables\nos.environ[\"PYTHONHASHSEED\"] = str(SEED)\n# os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T10:15:24.275360Z","iopub.execute_input":"2026-02-14T10:15:24.275591Z","iopub.status.idle":"2026-02-14T10:15:24.280132Z","shell.execute_reply.started":"2026-02-14T10:15:24.275566Z","shell.execute_reply":"2026-02-14T10:15:24.279191Z"}},"outputs":[],"execution_count":13},{"id":"c72eb59f-1500-4e39-b46c-556d5a33e05f","cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\n# os.cpu_count()\ntorch.cuda.is_available()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T10:15:24.281239Z","iopub.execute_input":"2026-02-14T10:15:24.281477Z","iopub.status.idle":"2026-02-14T10:15:24.301660Z","shell.execute_reply.started":"2026-02-14T10:15:24.281445Z","shell.execute_reply":"2026-02-14T10:15:24.300980Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}],"execution_count":14},{"id":"90794fb4-bc3f-48cf-a840-cbe31a22fcd7","cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nimport rasterio\nimport numpy as np\nfrom rasterio.enums import Resampling\nimport torch.nn as nn\nimport pytorch_lightning as pl\nfrom torchvision.models import resnet50\nfrom torch.utils.data import DataLoader\nfrom lightning.pytorch import Trainer\nfrom torchvision import transforms  \nfrom torchgeo.trainers.moco import MoCoTask\nfrom torchgeo.models import ResNet18_Weights\nimport kornia.augmentation as K\nimport torch.nn.functional as F\nimport torchgeo.transforms as T\nfrom lightning.pytorch.loggers import CSVLogger\nimport glob\nimport shutil\nimport random\nimport time\nfrom prettytable import PrettyTable\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nimport numpy as np\nimport torch\nfrom PIL import Image\nfrom torchvision import transforms\nimport os\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T10:15:24.302757Z","iopub.execute_input":"2026-02-14T10:15:24.302951Z","iopub.status.idle":"2026-02-14T10:15:24.316373Z","shell.execute_reply.started":"2026-02-14T10:15:24.302930Z","shell.execute_reply":"2026-02-14T10:15:24.315688Z"}},"outputs":[],"execution_count":15},{"id":"af5f7783-8984-445f-86c3-c0d095d433fe","cell_type":"code","source":"random.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\npl.seed_everything(SEED, workers=True)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.use_deterministic_algorithms(True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T10:15:24.317206Z","iopub.execute_input":"2026-02-14T10:15:24.317460Z","iopub.status.idle":"2026-02-14T10:15:24.337415Z","shell.execute_reply.started":"2026-02-14T10:15:24.317426Z","shell.execute_reply":"2026-02-14T10:15:24.336410Z"}},"outputs":[{"name":"stderr","text":"Seed set to 42\n","output_type":"stream"}],"execution_count":16},{"id":"88cf7e22-1465-449f-86fb-68da46ac024e","cell_type":"code","source":"target_size = 224\ntarget_batch_size= 8 #128 #prefer 256 or 128\ntarget_num_workers=4\ntarget_max_epoch=6\nuse_peft = True  \nfrom datetime import datetime","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T10:15:24.338537Z","iopub.execute_input":"2026-02-14T10:15:24.338845Z","iopub.status.idle":"2026-02-14T10:15:24.349318Z","shell.execute_reply.started":"2026-02-14T10:15:24.338821Z","shell.execute_reply":"2026-02-14T10:15:24.348363Z"}},"outputs":[],"execution_count":17},{"id":"795ed230-3932-4ff3-bb39-e13f7b081e2a","cell_type":"code","source":"def split_dataset(root_dir,csv_output)\n    # --- COLLECT IMAGE INFO ---\n    data=[]\n    # Iterate over each class folder\n    for class_name in os.listdir(root_dir):\n        class_path = os.path.join(root_dir, class_name)\n        # print(class_path)\n        if not os.path.isdir(class_path):\n            continue  # skip files in root_dir\n    \n        # Iterate over images in the class folder\n        for fname in os.listdir(class_path):\n            # if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n            if fname.lower().endswith((\".tif\", \".tiff\")):\n                # path = os.path.join(class_path, fname)\n                rel_path = os.path.join(class_name, fname)\n                data.append({\n                    \"id\": os.path.splitext(fname)[0].split(\"_\")[-1],\n                     \"fname\": fname,\n                    \"rel_path\": rel_path,\n                    \"label\": class_name\n                })\n    # --- CREATE DATAFRAME ---\n    df = pd.DataFrame(data)\n    # print(df.columns)\n    # --- STRATIFIED SPLIT: 80% SSL, 20% Downstream ---\n    ssl_df, downstream_df = train_test_split(\n        df,\n        test_size=0.2,\n        stratify=df['label'],\n        random_state=42\n    )\n    \n    ssl_df['task'] = 'ssl'\n    downstream_df['task'] = 'downstream'\n    \n    df = pd.concat([ssl_df, downstream_df]).reset_index(drop=True)\n    \n    ssl_df = df[df['task'] == 'ssl'].copy()\n    \n    skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n    \n    ssl_splits = np.empty(len(ssl_df), dtype=object)\n    split_names = ['subset1', 'subset2', 'subset3', 'subset4']\n    \n    for fold_idx, (_, val_idx) in enumerate(skf.split(ssl_df, ssl_df['label'])):\n        ssl_splits[val_idx] = split_names[fold_idx]\n    \n    df.loc[ssl_df.index, 'split'] = ssl_splits\n    \n    down_df = df[df['task'] == 'downstream'].copy()\n    # Step 1: Train (70%) vs Temp (30%)\n    train_df, temp_df = train_test_split(\n        down_df,\n        test_size=0.30,\n        stratify=down_df['label'],\n        random_state=42\n    )\n    # Step 2: Temp â†’ Val (15%) + Test (15%)\n    val_df, test_df = train_test_split(\n        temp_df,\n        test_size=0.50,  # half of 30% = 15%\n        stratify=temp_df['label'],\n        random_state=42\n    )\n    # Assign splits back\n    df.loc[train_df.index, 'split'] = 'train'\n    df.loc[val_df.index, 'split'] = 'val'\n    df.loc[test_df.index, 'split'] = 'test'\n    \n    # --- FINAL CHECK ---\n    print(df['task'].value_counts())\n    print(df['split'].value_counts())\n    # print(df.head(10))\n    \n    # --- SAVE CSV ---\n    df.to_csv(csv_output, index=False)\n    print(f\"CSV saved to {csv_output}\")\n    # print(df.head())\n    # print(df[df['split'] == 'train']['label'].value_counts())\n\nclass SSLDataset(Dataset):\n    def __init__(self, data_dir, split_path,split, transforms=None):\n        \"\"\"\n        Args:\n            data_dir (str): Eurosat folder paths.\n            split_path (str): CSV file path containing splits metadata\n            split (str): all, full_ssl, subset1, subset2, subset3, subset4, train, test, val\n            transforms (callable, optional): Optional transform to apply to patches.\n        \"\"\"\n        self.data_dir = data_dir\n        self.split_path = split_path\n        self.transforms = transforms\n        # self.target_h= None\n        # self.target_w = None\n        \n        # Precompute all paths based on split\n        self.samples = []\n        df=pd.read_csv(split_path)\n        if split==\"all\":\n            pass\n        elif split==\"full_ssl\":\n            df=df[df['task'] == \"ssl\"]\n        else:\n            df=df[df['split'] == split]\n        self.samples = df['rel_path'].tolist()\n        \n\n    def __len__(self):\n        return len(self.samples)\n    \n\n    # def __getitem__(self, idx):\n    #     sample_path = os.path.join(self.data_dir, self.samples[idx])\n        \n    #     with Image.open(sample_path) as img:\n    #         patch_tensor = img.convert(\"RGB\")\n    #     if self.transforms:\n    #         patch_tensor = self.transforms(patch_tensor)\n\n    #     return {\"image\": patch_tensor}\n    def __getitem__(self, idx):\n        sample_path = os.path.join(self.data_dir, self.samples[idx])\n    \n        # --- Read TIFF with rasterio ---\n        with rasterio.open(sample_path) as src:\n            # Read all bands as float32\n            bands = [src.read(b).astype(np.float32) for b in range(1, src.count + 1)]\n        \n        # Stack bands to shape [C, H, W]\n        img_array = np.stack(bands, axis=0)\n    \n        # --- Convert to torch tensor ---\n        patch_tensor = torch.tensor(img_array, dtype=torch.float32)\n    \n        # --- Apply transforms if provided ---\n        if self.transforms:\n            patch_tensor = self.transforms(patch_tensor)\n    \n        return {\"image\": patch_tensor}\n\n\ndef calculate_stats(dataset, n_samples=500):\n    mean = 0\n    std = 0\n    total = len(dataset)\n    n = min(total, n_samples)\n\n    # Randomly choose n indices\n    np.random.seed(42)\n    indices = np.random.choice(total, size=n, replace=False)\n    # count=0\n    for i in indices:\n        # count=count+1\n        # print(count)\n        sample = dataset[i]\n        # print(sample)\n        img = sample[\"image\"]   # TorchGeo-style dictionary\n\n        mean += img.mean(dim=(1, 2))\n        std += img.std(dim=(1, 2))\n    mean /= n\n    std /= n\n    return mean, std","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T10:46:10.336701Z","iopub.execute_input":"2026-02-14T10:46:10.337008Z","iopub.status.idle":"2026-02-14T10:46:10.573656Z","shell.execute_reply.started":"2026-02-14T10:46:10.336973Z","shell.execute_reply":"2026-02-14T10:46:10.572908Z"}},"outputs":[{"name":"stdout","text":"Index(['id', 'fname', 'rel_path', 'label'], dtype='object')\ntask\nssl           22077\ndownstream     5520\nName: count, dtype: int64\nsplit\nsubset1    5520\nsubset4    5519\nsubset2    5519\nsubset3    5519\ntrain      3864\ntest        828\nval         828\nName: count, dtype: int64\nCSV saved to /kaggle/working/eurosat_all_bands_split.csv\n     id                          fname  \\\n0  2352            Industrial_2352.tif   \n1  1808           Residential_1808.tif   \n2   102                 Forest_102.tif   \n3  1838  HerbaceousVegetation_1838.tif   \n4  1217                Forest_1217.tif   \n\n                                            rel_path                 label  \\\n0                     Industrial/Industrial_2352.tif            Industrial   \n1                   Residential/Residential_1808.tif           Residential   \n2                              Forest/Forest_102.tif                Forest   \n3  HerbaceousVegetation/HerbaceousVegetation_1838...  HerbaceousVegetation   \n4                             Forest/Forest_1217.tif                Forest   \n\n  task    split  \n0  ssl  subset4  \n1  ssl  subset1  \n2  ssl  subset1  \n3  ssl  subset1  \n4  ssl  subset4  \nlabel\nSeaLake                 504\nHerbaceousVegetation    420\nAnnualCrop              420\nResidential             420\nForest                  420\nHighway                 350\nRiver                   350\nIndustrial              350\nPermanentCrop           350\nPasture                 280\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":30},{"id":"7dbd6036-66d2-4393-a9ee-3c57cf5740a2","cell_type":"code","source":"# --- CONFIG ---\nroot_dir = \"/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSATallBands\"  # folder with all images\ncsv_output = \"/kaggle/working/eurosat_all_bands_split.csv\"\nsplit_dataset(root_dir, csv_output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T10:46:17.221383Z","iopub.execute_input":"2026-02-14T10:46:17.221685Z","iopub.status.idle":"2026-02-14T10:46:17.230660Z","shell.execute_reply.started":"2026-02-14T10:46:17.221658Z","shell.execute_reply":"2026-02-14T10:46:17.229509Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"     id                          fname  \\\n0  2352            Industrial_2352.tif   \n1  1808           Residential_1808.tif   \n2   102                 Forest_102.tif   \n3  1838  HerbaceousVegetation_1838.tif   \n4  1217                Forest_1217.tif   \n\n                                            rel_path                 label  \\\n0                     Industrial/Industrial_2352.tif            Industrial   \n1                   Residential/Residential_1808.tif           Residential   \n2                              Forest/Forest_102.tif                Forest   \n3  HerbaceousVegetation/HerbaceousVegetation_1838...  HerbaceousVegetation   \n4                             Forest/Forest_1217.tif                Forest   \n\n  task    split  \n0  ssl  subset4  \n1  ssl  subset1  \n2  ssl  subset1  \n3  ssl  subset1  \n4  ssl  subset4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>fname</th>\n      <th>rel_path</th>\n      <th>label</th>\n      <th>task</th>\n      <th>split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2352</td>\n      <td>Industrial_2352.tif</td>\n      <td>Industrial/Industrial_2352.tif</td>\n      <td>Industrial</td>\n      <td>ssl</td>\n      <td>subset4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1808</td>\n      <td>Residential_1808.tif</td>\n      <td>Residential/Residential_1808.tif</td>\n      <td>Residential</td>\n      <td>ssl</td>\n      <td>subset1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>102</td>\n      <td>Forest_102.tif</td>\n      <td>Forest/Forest_102.tif</td>\n      <td>Forest</td>\n      <td>ssl</td>\n      <td>subset1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1838</td>\n      <td>HerbaceousVegetation_1838.tif</td>\n      <td>HerbaceousVegetation/HerbaceousVegetation_1838...</td>\n      <td>HerbaceousVegetation</td>\n      <td>ssl</td>\n      <td>subset1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1217</td>\n      <td>Forest_1217.tif</td>\n      <td>Forest/Forest_1217.tif</td>\n      <td>Forest</td>\n      <td>ssl</td>\n      <td>subset4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":31},{"id":"07b09f9d-69a1-48eb-bbf0-50d07bf8eb8e","cell_type":"markdown","source":"### Settings","metadata":{}},{"id":"c89c3361-f4bb-4fd4-9ca2-75066c36d8f3","cell_type":"code","source":"target_size = 224\ntarget_batch_size= 8 #128 #prefer 256 or 128\ntarget_num_workers=4\ntarget_max_epoch=6\nuse_peft = True  \nfrom datetime import datetime\n\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nlogger = CSVLogger(\"logs\", name=f\"metrics_{timestamp}\")\n\naug = K.AugmentationSequential(\n    K.RandomResizedCrop(size=(target_size, target_size), scale=(0.4, 1.0)),\n    K.RandomHorizontalFlip(),\n    K.RandomVerticalFlip(),\n    K.RandomGaussianBlur(kernel_size=(7,7), sigma=(0.1, 1.5), p=0.3),\n    K.RandomBrightness(brightness=(0.85, 1.15), p=0.5),\n    data_keys=['input'],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T10:47:34.818010Z","iopub.execute_input":"2026-02-14T10:47:34.818310Z","iopub.status.idle":"2026-02-14T10:47:34.828183Z","shell.execute_reply.started":"2026-02-14T10:47:34.818284Z","shell.execute_reply":"2026-02-14T10:47:34.827386Z"}},"outputs":[],"execution_count":36},{"id":"0b5a9dfb-55db-4e1e-baa6-491857d7d83d","cell_type":"code","source":"temp_dataset = SSLDataset(\n    data_dir = \"/kaggle/input/datasets/apollo2506/eurosat-dataset/EuroSATallBands\", \n    split_path= \"/kaggle/working/eurosat_all_bands_split.csv\",\n    split = \"all\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T10:48:28.145196Z","iopub.execute_input":"2026-02-14T10:48:28.145464Z","iopub.status.idle":"2026-02-14T10:48:28.192596Z","shell.execute_reply.started":"2026-02-14T10:48:28.145439Z","shell.execute_reply":"2026-02-14T10:48:28.191918Z"}},"outputs":[],"execution_count":37},{"id":"ac23bfcd-e4d5-4a01-b49e-8595d0253a92","cell_type":"code","source":"mean, std = calculate_stats(temp_dataset, n_samples=50)\nprint(mean, std )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T10:50:42.199789Z","iopub.execute_input":"2026-02-14T10:50:42.200161Z","iopub.status.idle":"2026-02-14T10:50:42.459658Z","shell.execute_reply.started":"2026-02-14T10:50:42.200132Z","shell.execute_reply":"2026-02-14T10:50:42.458818Z"}},"outputs":[{"name":"stdout","text":"tensor([1306.3080, 1078.1479, 1025.4133,  911.3115, 1162.5461, 1997.2366,\n        2391.7368, 2310.8821,  720.3613,   13.1632, 1779.5774, 1090.2094,\n        2603.8066]) tensor([ 48.8467, 118.6814, 150.8174, 222.9257, 186.8235, 335.2391, 437.8371,\n        509.6657,  97.3510,   1.2455, 332.6506, 254.2236, 484.9431])\n","output_type":"stream"}],"execution_count":48},{"id":"0716eda6-1694-4829-8b66-c6b6fd4369a7","cell_type":"code","source":"# based on 10k samples\nmean= [1333.8029, 1488.1448, 1745.9066, 1985.6210, 2322.0129, 2837.1787,\n        3065.8462, 3192.4492, 3225.1826, 3344.8479,    0.0000, 2683.2991,\n        2116.8357]\nstd = [384.9683, 472.5244, 497.7275, 590.9384, 578.0192, 641.7764, 699.6282,\n        752.0769, 709.3992, 752.4539,   0.0000, 568.3574, 542.2833]\n\n\n# to avoid 0 std\nstd = [max(s, 1e-5) for s in std]   \n\n# define transform\ntransform = transforms.Compose([\n    transforms.Resize((target_size, target_size)),\n    transforms.Normalize(mean=mean, std=std)\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b09f5f7d-a5bf-44f0-bcd7-e8b24acc3202","cell_type":"markdown","source":"","metadata":{}},{"id":"186dd8fb-e8e9-4fc1-aa47-8da54f22c9fb","cell_type":"code","source":"import os\nimport time\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader\nfrom pytorch_lightning import Trainer\n\ndef run_ssl(\n    data_dir,\n    split_path,\n    split=\"all\",\n    model=\"resnet18\",\n    weights=None,\n    in_channels=13,\n    transform=None,\n    batch_size=64,\n    num_workers=4,\n    target_size=224,\n    lr=1e-4,\n    memory_bank_size=2048,\n    temperature=0.15,\n    use_peft=False,\n    augmentation1=None,\n    augmentation2=None,\n    max_epochs=10,\n    # logger=None,\n    experiment_name= None\n):\n    \"\"\"\n    Run SSL experiment.\n\n    Args:\n        split: \"all\" for full dataset or \"subst1\"/\"subst2\"/... for sequential streaming\n        weights: ResNet18_Weights object\n        transform: preprocessing/normalization transform\n        augmentation1/2: MoCo augmentations\n        use_peft: bool, freeze backbone except last block\n        Other args: training hyperparameters\n    \"\"\"\n\n    # -----------------------------\n    # Dataset / DataLoader\n    # -----------------------------\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    logger = CSVLogger(\"logs\", name=f\"{experiment_name}/metrics_{timestamp}\")\n    dataset = SSLDataset(\n        data_dir=data_dir,\n        split_path=split_path,\n        split=split,\n        transforms=transform\n    )\n    print(f\"Dataset split '{split}' size:\", len(dataset))\n\n    data_loader = DataLoader(\n        dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        pin_memory=True,\n        num_workers=num_workers,\n        worker_init_fn=lambda worker_id: np.random.seed(seed + worker_id)\n    )\n\n    num_batches = len(data_loader)\n    print(\"Number of batches:\", num_batches)\n\n    # -----------------------------\n    # Initialize MoCo task\n    # -----------------------------\n    task = MoCoTask(\n        model=model,\n        weights=weights,\n        in_channels= in_channels,#weights.meta['in_chans'] if weights else 3,\n        version=2,\n        size=target_size,\n        augmentation1=augmentation1,\n        augmentation2=augmentation2,\n        lr=lr,\n        memory_bank_size=memory_bank_size,\n        temperature=temperature\n    )\n\n    # -----------------------------\n    # PEFT / Full Fine-Tuning Logic\n    # -----------------------------\n    if use_peft:\n        print(\"Using PEFT: freezing backbone except last block, training projection head...\")\n        for name, param in task.backbone.named_parameters():\n            param.requires_grad = \"layer4\" in name\n    else:\n        print(\"Full fine-tuning: backbone and projection head trainable...\")\n        for param in task.backbone.parameters():\n            param.requires_grad = True\n\n    # Momentum backbone always frozen\n    for param in task.backbone_momentum.parameters():\n        param.requires_grad = False\n\n    # Projection head always trainable\n    for param in task.projection_head.parameters():\n        param.requires_grad = True\n\n    summary_trainable(task)\n\n    # -----------------------------\n    # Trainer\n    # -----------------------------\n    trainer = Trainer(\n        max_epochs=max_epochs,\n        enable_progress_bar=True,\n        log_every_n_steps=num_batches,\n        precision=32,\n        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n        deterministic=True,\n        logger=logger\n    )\n\n    # -----------------------------\n    # Training\n    # -----------------------------\n    start_time = time.time()\n    trainer.fit(task, data_loader)\n    end_time = time.time()\n    print(f\"Training time: {(end_time-start_time)/60:.2f} min\")\n\n    print(task.trainer.logged_metrics)\n\n    # -----------------------------\n    # Save checkpoint / weights\n    # -----------------------------\n    os.makedirs(\"checkpoints\", exist_ok=True)\n    torch.save(task.backbone.state_dict(), f\"{experiment_name}/checkpoints/ssl_backbone_{timestamp}.pth\")\n    torch.save(task.projection_head.state_dict(), f\"{experiment_name}/checkpoints/projection_head_{timestamp}.pth\")\n    trainer.save_checkpoint(f\"{experiment_name}/checkpoints/ssl_ckpt_{timestamp}.ckpt\")\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}